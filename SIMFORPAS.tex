%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                Template para PFC                      %
%                                                       %
%    Comandos para pasar a pdf:                         %
%      1.- Pasamos a ps.                                %
%         dvips ComunicaDocumentacionPFC.dvi            %
%      2.- Pasamos a pdf.                               %
%         ps2pdf ComunicaDocumentacionPFC.ps            %
%Llamad al DocToPdf.bat para hacerlo de manera automática  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%aloo
\documentclass[12pt,a4paper,spanish]{book} %%%Esto indica el tipo de documento.
\usepackage[left=3cm,top=2.5cm,right=3cm,bottom=3.5cm]{geometry} 
%Va a ser un libro (book), el tamaño es a4, la lengua castellano (spanish)%%%
\usepackage{babel} %%%Incluimos el paquete Babel
%que sirve para separar correctamente
%las palabras de multitud de idiomas%%%
\usepackage[latin1]{inputenc}
\usepackage{eurosym}
%%%Este paquete permite poner acentos directamente%%%
\usepackage{amsmath}%%%Macros AMS%%%
\usepackage{amsthm}%%%Macros AMS para teoremas%%%
\usepackage{amsfonts}%%%Permite usar fuentes AMS%%%
\usepackage{amssymb}
%\usepackage[dvips]{epsfig} %%%Inclusión de figuras postscript% con
%visualización posterior%%%\usepackage{indentfirst}%%%Espaciado de
\usepackage[dvips]{graphicx}
\usepackage{titlesec}
\usepackage{lettrine}
\usepackage{eso-pic} 
\usepackage{xcolor}
\usepackage{setspace}
\usepackage{parskip}
\usepackage{float}
\usepackage{ifthen}
\usepackage{type1cm}
\usepackage{times}



%Código java%
\usepackage{color}
\definecolor{gray97}{gray}{.97}
\definecolor{gray75}{gray}{.75}

\usepackage{listings}
\lstset{ frame=Ltb,
     framerule=0pt,
     aboveskip=0.5cm,
     framextopmargin=3pt,
     framexbottommargin=3pt,
     framexleftmargin=0.4cm,
     framesep=0pt,
     rulesep=.4pt,
     backgroundcolor=\color{gray97},
     rulesepcolor=\color{black},
     %
     stringstyle=\ttfamily,
     showstringspaces = false,
     basicstyle=\scriptsize\ttfamily,
     commentstyle=\color{green},
     keywordstyle=\color{blue},
     %
     breaklines=true,     
   }
 
% minimizar fragmentado de listados
\lstnewenvironment{listing}[1][]
   {\lstset{#1}\pagebreak[0]}{\pagebreak[0]}
 
\lstdefinestyle{consola}
   {basicstyle=\scriptsize\bf\ttfamily,
    backgroundcolor=\color{gray75},
   }
 
\lstdefinestyle{Java}
   {language=Java,
   }


\let\oldcleardoublepage\cleardoublepage
\renewcommand{\cleardoublepage}{\newpage{\pagestyle{empty}\oldcleardoublepage}}

%Cabecera%
\date{}
\usepackage{fancyhdr}
\setlength{\headheight}{15pt}
\pagestyle{fancyplain}
\newcommand{\diezpuntos}{\fontsize{8pt}{\baselineskip}\selectfont}
\addtolength{\headheight}{1\baselineskip}
\lhead{\diezpuntos ITIGestión}
%\chead{\diezpuntos }%
\rhead[\diezpuntos \bfseries \leftmark]{\diezpuntos \bfseries \rightmark}
\renewcommand{\headrulewidth}{0.5 pt}
\renewcommand{\footrulewidth}{0pt}
\lfoot{\diezpuntos}

%%%%%%%%%%
%Comandos%
%%%%%%%%%%

%Fuente por defecto%
%\renewcommand{\familydefault}{\sfdefault}
%*Marquesina*%
\newcommand\BackgroundPicR{ 
\put(540,0){ 
\parbox[b][\paperheight]{3cm}{% 
\vfill 
\includegraphics[width=3cm,height=\paperheight, 
keepaspectratio]{img/Clouds.eps}% 
\vfill 
}}} 

%\newcommand\BackgroundPicL{ 
%\put(-5,0){ 
%\parbox[b][\paperheight]{3cm}{% 
%\vfill 
%\includegraphics[width=3cm,height=\paperheight, 
%keepaspectratio]{img/Clouds.eps}% 
%\vfill 
%}}} 
%
%\newcommand\BackgroundPic{\ifthenelse{\isodd{\thepage}}
% {\BackgroundPicR}{\BackgroundPicL}}

%Listas sin enumerar%
\renewcommand{\labelitemi}{$\bullet$}
\renewcommand{\labelitemii}{$\bullet$}
\renewcommand{\labelitemiii}{$\bullet$}
%Listas enumeradas%
\renewcommand{\theenumi}{\arabic{enumi}}
\renewcommand{\labelenumi}{%
\textbf{\theenumi}.-
}
\renewcommand{\theenumii}{\arabic{enumii}}
\renewcommand{\labelenumii}{%
\textbf{\theenumi}.\theenumii.-
}
\renewcommand{\theenumiii}{\arabic{enumiii}}
\renewcommand{\labelenumiii}{%
\textbf{\theenumi}.\theenumii.\theenumiii.-
}

%Citas%
\let\oldquote\quote
\renewcommand\quote{\par\singlespacing\small\oldquote}
\let\oldquotation\quotation
\renewcommand\quotation[1]{\oldquotation\small\hfill{\emph{\color{blue!
10!black}{#1}}}}
 \let\oldverse\verse
\renewcommand\verse{\par\singlespacing\small\oldverse}

%Capital%
\renewcommand{\LettrineFontHook}{\color{blue! 30!black}}

%Imagenes%
\newcommand{\imgIncl}[3]{
  \begin{figure}[here]
		\begin{center}
		\includegraphics[width=#1cm,angle=#2]{#3}
		\label{fig:#3}
		\end{center}
	\end{figure}
	
	}

\newcommand{\imgCentrada}[3]{
\begin{figure}[H]
\begin{center}
\includegraphics[width=12cm]{#2}
\caption{#3}
\label{#1}
\end{center}
\end{figure}
}

\newcommand{\imgCentradaGrande}[3]{
\begin{figure}[H]
\begin{center}
\includegraphics[width=16cm]{#2}
\caption{#3}
\label{#1}
\end{center}
\end{figure}
}

\newcommand{\imgCentradaMed}[3]{
\begin{figure}[H]
\begin{center}
\includegraphics[width=9cm]{#2}
\caption{#3}
\label{#1}
\end{center}
\end{figure}
}


\newcommand{\imgCentradaPeq}[3]{
\begin{figure}[H]
\begin{center}
\includegraphics[width=6cm]{#2}
\caption{#3}
\label{#1}
\end{center}
\end{figure}
}
	
%Parte%
\newcommand{\bigrule}{\titlerule[0.5mm]}
\titleformat{\part}[display] % cambiamos el formato de los capítulos
{\bfseries\Huge} % por defecto se usarán caracteres de tamaño \Huge en negrita
{% contenido de la etiqueta
\titlerule % línea horizontal
\filleft % texto alineado a la derecha
\Large{Parte}  % "Parte" en tamaño \Large en lugar de \Huge
\Large\thepart} % número de capítulo en tamaño \Large
{0mm} % espacio mínimo entre etiqueta y cuerpo
{\filleft} % texto del cuerpo alineado a la derecha
[\vspace{0.5mm} \bigrule \vspace{4cm}] % después del cuerpo, dejar espacio vertical y trazar línea horizontal gruesa

%Capitulo%
\titleformat{\chapter}[hang] % cambiamos el formato de los capítulos
{\bfseries\Large} % por defecto se usarán caracteres de tamaño \Huge en negrita
{% contenido de la etiqueta
\color{blue! 30!black}
\Large\chaptertitlename\ %"Capítulo" o "Apéndice" en tamaño \Large en lugar de \Huge
\Large\thechapter .} % número de capítulo en tamaño \Large
{2mm} % espacio mínimo entre etiqueta y cuerpo
{\filright\color{blue! 30!black}} % texto del cuerpo alineado a la derecha
[\vspace{0.5mm}] % después del cuerpo, dejar espacio vertical y trazar línea horizontal gruesa

%Secciones%
\titleformat{\section}[hang]
{\scshape\bfseries\Large}
{\color{blue! 30!black}\thesection. }
{0mm}{\filright\color{blue! 30!black}}[\vspace{0.5mm}]

%SubSecciones%
\titleformat{\subsection}[hang]
{\scshape\bfseries\large}
{\color{blue! 30!black}\thesubsection .}
{0mm}{\filright\color{blue! 30!black}}[\vspace{0.5mm}]

%SubsubSecciones%
\titleformat{\subsubsection}[hang]
{\scshape\bfseries}
{\color{blue! 30!black}\thesubsubsection .}
{0mm}{\filright\color{blue! 30!black}}[\vspace{0.5mm}]

%%%%%%%%%%%%%%%%%
%Fin de comandos%
%%%%%%%%%%%%%%%%%

\author{Manuel Mateos Gutiérrez.}
\title{SIMFORPAS}
\begin{document}
%%%Aquí empieza el documento%%%
\pagenumbering{roman}
%\maketitle
%%%Portada%%%
\begin{titlepage}
\bfseries
\begin{center}
    \includegraphics[width=0.3\textwidth]{img/LOGO.eps}
    \bigbreak
    \bigbreak
    \bigbreak
    ESCUELA TÉCNICA SUPERIOR DE INGENIERÍA INFORMÁTICA
    \bigbreak
    \bigbreak
    INGENIERÍA TÉCNICA EN INFORMÁTICA DE GESTIÓN
    \bigbreak
    \bigbreak
    \bigbreak
    \bigbreak
    \bigbreak
    \bigbreak
    {\LARGE SIMFORPAS}
    \smallbreak
    {\large Simulador para RPAS}
    \bigbreak
    \bigbreak    
    \bigbreak
    \bigbreak
    \bigbreak
    Realizado por
    \smallbreak
    MANUEL MATEOS GUTIÉRREZ\\
    32076954-G

    \bigbreak
    \bigbreak
    Dirigido por
    \smallbreak
    IRENE ALEJO TEISSI\`ERE
    \smallbreak
    PABLO TRINIDAD MARTÍN-ARROYO
    \bigbreak
    \bigbreak
    Departamento
    \smallbreak
    LENGUAJES Y SISTEMAS INFORMÁTICOS
\end{center}
    \vfill
\begin{flushright}
Sevilla, Mayo de 2014
\end{flushright}
\end{titlepage}
%%%FIN de Portada%%%

\vspace*{7cm}
%AGRADECIMIENTOS
\setlength{\parindent}{1cm}
\chapter*{Agradecimientos}
Agradecimientos
\cleardoublepage

\tableofcontents
\listoffigures

\cleardoublepage

\pagenumbering{arabic}

\part{Introducción}


 
%\AddToShipoutPicture{\BackgroundPic}

\chapter{Introducción}

\lettrine{A}{UNQUE} el concepto de aviones no tripulados o UAV's (Unmanned Aerial Vehicles) es bastante antiguo, puesto que se empezaron a usar durante la primera guerra mundial, cada día oímos más hablar sobre ellos en los medios de comunicación, esto se debe al gran crecimiento que está sufriendo el sector de la aeronáutica en torno a estos dispositivos, tanto para uso militar, como los famosos "drones" de Estados Unidos, como civil.

Su uso es amplio y variado, desde rodaje de planos aéreos en películas de cine hasta control de incendios, control de costas, recogida de información, ayuda en operaciones de rescate, control de multitudes...

\imgCentrada{fig.1.1}{img/incendio.eps}{Soporte aéreo en el control de incendios.}

A finales del siglo XX fue cuando los UAV's empiezan a operar con todas las características de autonomía. Esto nos provee de muchas ventajas, por ejemplo, presencia en lugares de difícil acceso sin necesidad de llevar al terreno a un piloto de UAV, reducción del riesgo humano en determinadas situaciones, disminución del la incursión humana sobre parques naturales y zonas protegidas... . Poco a poco los UAV's tienden a prescindir de la presencia de un piloto que tenga la obligación de estar visualizando el avión y a implementar sistemas de control remoto mediante estaciones de control de tierra o GCS's (Ground Control Stations) y de vuelo automatizado, lo que nos llevará a no depender del factor humano. 

Las GCS son controladas por operadores expertos en estos dispositivos que se encargan de dise\'nar e implementar las misiones que realizarán los aviones, así como llevar el control del curso de la misma, conocer las características de la aeronave, deben saber interpretar los indicadores de telemetría, estar familiarizados con el protocolo de comunicación y saber reaccionar ante posibles fallos durante la misión para salvaguardar en todo momento la seguridad tanto del vehículo aéreo como del entorno en el que se mueve.

Estos operadores requieren de una formación en profundidad y fiable ya que tienen la responsabilidad sobre las acciones que realice la aeronave, por ello se debe exigir un entrenamiento concienzudo. Si este entrenamiento es realizado con dispositivos reales corremos el riesgo de que frente a cualquier fallo, error humano o de carácter informático, haya una pérdida en algún componente del sistema, ya sea que se estrelle la aeronave, que da\'ne alguna estructura o a alguna persona, lo que resultaría en una importante pérdida económica y/o humana. 

Para ilustrar la necesidad de la implementación de un sistema de evaluación de pilotos tendremos en cuenta, entre otros factores los múltiples accidentes que ha habido en los últimos años, la mayoría de ellos debido a descuidos o a la falta de experiencia de los operadores de GCS. Uno de los casos que pueden darse es el de la falta de pruebas del sistema por parte de los desarrolladores la cual puede llevar a que los operadores puedan mandar comandos erróneos al avión provocando así un accidente, como pasó en el accidente del UAV tipo Predator en Septiembre del año 2000 cuando un piloto por equivocación liberó la memoria del UAV provocando un corte en las comunicaciones el cual no pudieron recuperar antes de que el avión se estrellara (Datos de la FAA, Federal Aviation Administration, de Estados Unidos durante una conferencia sobre seguridad durante vuelos de UAV dada por Kevin W. Williams), si se hubiera podido probar el software de forma segura sin poner en peligro el avión éste error podría haberse evitado.

\imgCentrada{fig.1.2}{img/predator.eps}{UAV tipo Predator en vuelo.}

Otro ejemplo de error común que podemos encontrar en la información ofrecida por la FAA es el de la falta de experiencia de los operadores controlando los mandos, uno de los ejemplos de este tipo de error fue el accidente ocurrido en abril de 2006, el dispositivo de control de tierra constaba de dos estaciones iguales, una destinada al manejo de la aeronave y otra al de la cámara. En un momento dado se detectó un error en la comunicación entre el avión y la GCS y decidieron cambiar la función de las estaciones entre sí, pero la posición en la que se encontraba la estación que controlaba la cámara, concretamente una palanca que cerraba el diafragma de la misma, ordenaba al controlar el UAV que se parara el motor, de forma que en el momento del cambio perdieron el control de la aeronave estrellándola. 

\imgCentrada{fig.1.3}{img/predatorgcs.eps}{GCS usada para el UAV Predator.}

En este accidente los pilotos tenían poca experiencia de vuelo y ningún certificado acreditativo para poder manejar este tipo de instrumental, la alarma del indicador de que algo iba mal no era específica para ese error por lo que no se tuvo en cuenta. Un error tan importante como la no implantación de un protocolo de comprobaciones al iniciar una nueva estación de control para volar un UAV podría haber sido evitado si se incluyera en un curso obligatorio para operadores de estos dispositivos.

El proyecto SIMFORPAS pretende dar una solución a este problema presentando un entorno de simulación de vuelo de UAV's para operadores de GCS en formación, que proveerá de un contexto de vuelo seguro e idéntico a una situación real de control de misión de un UAV.
\newpage
\section{Motivación}

\lettrine{S}{egún} un estudio publicado por el medio online \emph{Update Defense} y realizado por la firma de investigación de mercados \emph{ICD Research} durante la próxima década el sector de la aviación no tripulada tendrá un aumento anual del 4,08\% lo que supondrá que en 2021 alcance alrededor de los 10.500 millones de dólares. El gran incremento de la demanda  se traducirá en una mayor necesidad de infraestructuras y tecnologías en torno a estos dispositivos.

En vistas de estas espectativas resulta interesante implicarse de una forma activa en un mercado en auge que supondrá la aceptación de un gran número de nuevas tecnologías y traerá nuevos desafíos en cuanto a investigación y desarrollo.

Uno de los requisitos que tendrá esta etapa será pa de disponer de personal cualificado para la manipulación de los dispositivos de pilotage remotos de aeronaves no tripuladas, el proyecto SIMFORPAS pretende ocupar ese hueco proveyendo de un entorno seguro y fiable que permita conceder una certificación avanzada a operadores de GCS de forma que se aseguren los conocimientos técnicos necesarios en una situación real de pilotage.

En este proyecto propondremos una solución usando una serie de tecnologías que nos proveerán de las herramientas necesarias para crear el sistema necesario para la consecución de nuestro objetivo.

\newpage
\section{Objetivos del proyecto}

\lettrine{E}{l} objetivo de este proyecto será el de crear una plataforma de simulación para la formación y entrenamiento de pilotos de RPAS (Remotely Piloted Aircraft System) ligeros que se comporte exactamente como lo haría el avión real. Que el sistema permita hacer uso de una GCS homologada para el manejo de UAV's usando un protocolo de comunicaciones para aviones no tripulados de menos de 25 Kg y usando un modelo de avión real.

También se requerirá de una herramienta que permita a un instructor ser capaz de controlar la simulación permitiéndole manejar su curso e introducir errores en el sistema. La simulación se deberá hacer en tiempo real.

Para garantizar la correcta consecución de los objetivos generales del proyecto se utilizará la herramienta de organización SCRUM junto a otras metodologías de desarrollo ágil.

\subsection{Objetivos orientados a la metodología}

Los objetivos que se tienen en mente al realizar esta aplicación con respecto a
las metodologías usadas son los siguientes:

\begin{itemize}
  \item Aplicar el marco de trabajo Scrum, usando para ello los conocimientos
  adquiridos al trabajar en empresas que utilizan dicha metodología y cursos.
  También se dispone del apoyo bibliográfico de libros como \emph{Agile Samurai} y \emph{Agile Software Development with Scrum}

  \item Aplicar metodologías de programación en pareja para agilizar el desarrollo y evitar errores en el código.

  \item Aplicar los principios S.O.L.I.D. como base de un código robusto, limpio y sujeto a cambios.

  \item Aplicar metodologías de eXtreme Programming para asegurar que el código acepte cambios de manera sencilla e intuitiva.

  \item Comprobar los beneficios colaterales a la realización de estas
  prácticas como, por ejemplo, la facilidad de a\'nadir nuevas tareas durante el
  proceso de desarrollo.
 
\end{itemize}

\subsection{Objetivos orientados a la técnica}

Los objetivos que se han querido validar al realizar esta aplicación son los
siguientes:

\begin{itemize}
  \item Aprender y utilizar tecnologías que garanticen una comunicación y procesado de datos en tiempo real como pueden ser C++ y DDS.
  
  \item Aprender y utilizar para el puesto de instructor herramientas que ayuden al desarrollo de una plataforma web para el control del simulador como Maven, Struts2, Spring4 e Hibernate4.
  
  \item Aprender y utilizar entornos de testeo de código como Google test, Google mock, Junit y Jmock para asegurar que el código funciona en todas las fases de desarrollo y modificación del software.

  \item Aplicar correctamente cada una de las metodologías estudiadas y sacar conclusiones de su uso.
  
\end{itemize}

\subsection{Objetivos personales}

Se ha querido asegurar que se cumplen los siguientes objetivos a lo largo del
desarrollo de la aplicación:

\begin{itemize}
  \item Adaptación: Adecuarse a las exigencias de estas nuevas metodologías. Los
  desarrolladores tienen la motivación de aprender nuevas técnicas que mejoren
  la calidad del software.
  
  \item Confianza: Conseguir conocimientos que me permitan en un futuro abatir exitosamente un proyecto software.
  
  \item Experiencia: Adquirir aptitudes para solucionar problemas y añadir valor a un grupo de trabajo en un entorno laboral.
  
  \item Conocimientos Técnicos: Trabajar y sintetizar nuevas tecnologías que me sirvan en el futuro para completarme como profesional en mi campo.

\end{itemize}
%COMPROBAR APARTADO DE CONCLUSIONES
Se tendrán en cuenta estos objetivos durante la realización del proyecto y se comprobará si han sido realizados. Esto se verá con detenimiento en los apartados de conclusiones, véase la parte V del presente documento.

\newpage
\section{Estructura del documento}

Éste documento se estructura en las siguientes partes:

\textbf{PREFACIO:} En éste capítulo se introduce el proyecto creando el contexto de su implementación, explicando en qué consiste, la motivación que nos ha llevado a desarrollarlo y los objetivos que se quieren cumplir en el mismo, así como éste mismo apartado de estructura del proyecto en el que explicamos qué vamos a encontrarnos en ésta memoria y cómo está distribuida y un índice de contenidos y de figuras.

\textbf{CONCEPTOS BÁSICOS:} Introducimos las metodologías que hemos usado durante el desarrollo del proyecto así como los conceptos básicos necesarios para comprender todo el documento, una enumeración de tecnologías usadas y un glosario de terminología, también se explicará el método de desarrollo iterativo e incremental que hemos llevado a cabo y en el que se basa la documentación del proyecto.

\textbf{SISTEMA A DESARROLLAR:} Aquí se enumerarán cada una de las etapas de desarrollo que ha ido sufriendo el proyecto SIMFORPAS desarrollando la planificación para cada iteración y cada problema que ha ido surgiendo durante el mismo, también se aportará el diagrama de Burndown para monitorizar en todo momento el estado del proyecto.

\textbf{CONCLUSIONES:} Realizaremos una retrospectiva final del proyecto analizando su estado final, la consecución de los objetivos, los cambios con respecto a la planificación inicial que se han realizado y las posibles mejoras y futuro del proyecto SIMFORPAS.

\textbf{APENDICES:} Para finalizar añadiremos un apéndice de definiciones, un manual de usuario y la bibliografía usada durante el desarrollo del proyecto y la memoria.

\newpage
\ClearShipoutPicture
\part{Conceptos básicos}
\chapter{Metodologías usadas}
%\AddToShipoutPicture{\BackgroundPic}

\lettrine{E}{n} éste capítulo empezaremos haciendo una introducción a las metodologías ágiles, explicando su filosofía y el por qué de su existencia así como una serie de técnicas para implementar este tipo de metodologías a nuestro proyecto software y qué beneficio nos aporta.

El proyecto fue desarrollado haciendo uso del sistema SCRUM de desarrollo iterativo, se explicará en qué consiste éste método y como ha sido aplicado a SIMFORPAS.

\section{Metodologías ágiles}

\lettrine{E}{l} proceso normal afianzado hasta ahora en el desarrollo software sigue unas pautas de rigidez que evita que el producto esté sometido a cambios ya que cuanto más avanzado está el desarrollo del proyecto más difícil y costoso resulta la introducción de modificaciones, para ello se definen unos requisitos que debe cumplir el producto final y antes de empezar el proyecto se decide las tecnologías a usar y la planificación del desarrollo, el cliente no toma parte en el proceso de implementación sino que cuando llega la fecha indicada para la finalización se le presenta y se evalúa si se ha conseguido el resultado que él esperaba.

Como pueden imaginar en la mayoría de los casos debido al desconocimiento real del problema no se definen correctamente los requisitos o las tecnologías usadas y surgían problemas imprevistos en la planificación que retrasan la fecha de entrega o acortan el tiempo de desarrollo obligando al equipo a dedicar más horas repercutiendo todo esto negativamente en el resultado final.

En otros casos la entrega se hace a tiempo pero debido a la ausencia del cliente durante el proceso de desarrollo el producto final no responde a lo que él imaginaba que se iba a desarrollar causando descontento por parte de nuestro cliente y afectando a futuros contratos que podamos hacer con él mismo.

Para hacer frente a esta serie de problemas en torno al desarrollo software nacen las "Metodologías Ágiles", En 2001 un grupo de desarrolladores se reúne en Utah para discutir los \emph{métodos de peso ligero} de desarrollo software y publicaron el \emph{Manifiesto ágil}, un documento que resume la filosofía ágil y establece cuatro valores y doce principios.

\subsection{Manifiesto ágil}

\imgCentrada{fig.2.1}{img/manifest.eps}{Manifiesto ágil.}

\subsubsection{VALORES:}

\begin{itemize}
\item \textbf{Valorar más a los individuos y su interacción que a los procesos y las herramientas:} Este es posiblemente el principio más importante del manifiesto. Por supuesto que los procesos ayudan al trabajo. Son una guía de operación. Las herramientas mejoran la eficiencia, pero sin personas con conocimiento técnico y actitud adecuada, no producen resultados.
\item \textbf{Valorar más el software que funciona que la documentación exhaustiva:} La documentación siempre será una medida importante pero no como guía para entender un código sino como complemento de un código claro y autoexplicativo. Al final lo que se debe valorar es un código ordenado y que funciona, que le da valor a un proyecto, por encima de una documentación que aporta datos y no información.
\item \textbf{Valorar más la colaboración con el cliente que la negociación contractual:} Las prácticas ágiles están especialmente indicadas para productos difíciles de definir con detalle en el principio, o que si se definieran así tendrían al final menos valor que si se van enriqueciendo con retro-información continua durante el desarrollo. También para los casos en los que los requisitos van a ser muy inestables por la velocidad del entorno de negocio. En el desarrollo ágil el cliente es un miembro más del equipo, que se integra y colabora en el grupo de trabajo. Los modelos de contrato por obra no encajan.
\item \textbf{Valorar más la respuesta al cambio que el seguimiento de un plan:} Para un modelo de desarrollo que surge de entornos inestables, que tienen como factor inherente el cambio y la evolución rápida y continua, resulta mucho más valiosa la capacidad de respuesta que la de seguimiento y aseguramiento de planes pre-establecidos. Los principales valores de la gestión ágil son la anticipación y la adaptación; diferentes a los de la gestión de proyectos ortodoxa: planificación y control para evitar desviaciones sobre el plan.

\end{itemize}

\subsubsection{PRINCIPIOS:}

\begin{enumerate}

\item La prioridad es satisfacer al cliente mediante tempranas y continuas
entregas de software que le aporten valor.
\item Dar la bienvenida a los cambios de requisitos. Se capturan los cambios
para que el cliente tenga una ventaja competitiva.
\item Liberar software que funcione frecuentemente, desde un par de semanas
a un par de meses, con el menor intervalo de tiempo posible entre
entregas.
\item Los miembros del negocio y los desarrolladores deben trabajar juntos
diariamente a lo largo del proyecto.
\item Construir el proyecto en torno a individuos motivados. Darles el entorno
y apoyo que necesiten y confiar a en ellos para conseguir finalizar
el trabajo.
\item El diálogo cara a cara es el método más eficiente y efectivo para
comunicar información dentro de un equipo de desarrollo.
\item El software que funciona es la principal medida de progreso.
\item Los procesos ágiles promueven un desarrollo sostenible. Los promotores,
desarrolladores y usuarios deberían ser capaces de mantener una paz
constante.
\item La atención continua a la calidad técnica y al buen diseño mejora
la agilidad.
\item La simplicidad es esencial.
\item Las mejores arquitecturas, requisitos y diseños surgen de los equipos
que se organizan ellos mismos.
\item En intervalos regulares, el equipo debe reflexionar sobre cómo ser
más efectivo y, según estas reflexiones, ajustar su comportamiento.


\end{enumerate}



\subsection{Desarrollo iterativo incremental con Scrum}

\subsubsection{Introducción}

\lettrine{P}{ara} abordar la realización del proyecto SIMFORPAS se hará uso del modelo organizativo de trabajo Scrum. Una de las características de éste modelo es la búsqueda de una serie de beneficios, como por ejemplo, la capacidad de aceptación de nuevos cambios durante el desarrollo ya sean requeridos por el cliente como por el mercado, esto nos asegura que el cliente al finalizar el proyecto va a tener el producto que satisface a sus necesidades ya que de otro modo los requisitos pueden haber cambiado desde la definición inicial.

El equipo de trabajo se auto asignará las tareas a realizar, esto provoca que cada integrante se mantenga motivado ya que él mismo se ha puesto su objetivo. El desarrollo iterativo exige tener una versión funcional o una serie de resultados presentables al finalizar cada etapa del desarrollo, esto se traduce en una mayor calidad del software.

Utilizando herramientas como la gráfica de burn down es posible observar la velocidad que está llevando el equipo de desarrollo, esto es útil para detectar posibles problemas de rendimiento que haya que solucionar entre todo el equipo o una reorganización de la planificación así como para poder estimar el tiempo de duración del proyecto.

\subsubsection{Roles}

\begin{itemize}
\item \textbf{Product owner:} El Product Owner representa la voz del cliente. Se asegura de que el equipo Scrum trabaje de forma adecuada desde la perspectiva del negocio. El Product Owner escribe historias de usuario, las prioriza, y las coloca en el Product Backlog.
\item \textbf{ScrumMaster:} El Scrum es facilitado por un ScrumMaster, cuyo trabajo primario es eliminar los obstáculos que impiden que el equipo alcance el objetivo del sprint. El ScrumMaster no es el líder del equipo (porque ellos se auto-organizan), sino que actúa como una protección entre el equipo y cualquier influencia que le distraiga. El ScrumMaster se asegura de que el proceso Scrum se utiliza como es debido. El ScrumMaster es el que hace que las reglas se cumplan.
\item \textbf{Equipo de desarrollo:} El equipo tiene la responsabilidad de entregar el producto. Un pequeño equipo de 3 a 9 personas con las habilidades transversales necesarias para realizar el trabajo (análisis, diseño, desarrollo, pruebas, documentación, etc).
\end{itemize}

Existen otros roles auxiliares como pueden ser proveedores, clientes, vendedores... sólo participarán directamente durante las revisiones de sprint.

\subsubsection{Desarrollo del proyecto con Scrum}

\lettrine{A}{l} principio se tiene una reunión con el cliente donde se recoge el objetivo del proyecto, los requisitos y las tareas que se llevarán a cabo para realizarlos, todo ello mediante historias de usuario en las que se asocia el rol a la necesidad del proyecto como se puede observar en el siguiente ejemplo: \emph{Como desarrollador quiero un módulo central capaz de cambiar y monitorizar el estado del modelo}, de esta forma se deciden las tareas a realizar. Luego el equipo y el cliente discuten la prioridad en las tareas hasta llegar a un consenso de qué es más importante desarrollar primero y qué dejar para más adelante, de esta forma nos aseguramos de ir cumpliendo las necesidades más importantes para poder tener cuanto antes una versión funcional del proyecto. También se valorarán según la dificultad de cada una de ellas, facilitando de esta forma la elección de qué se realizará antes, las acciones que sean esenciales y fáciles se harán primero, y las difíciles y poco necesarias se dejarán para el final, el tiempo de realización de cada tarea se hará en función a la dificultad de la misma.

Una vez definidas las historias de usuario se define el tamaño de los \emph{sprints}, normalmente un sprint es un espacio de tiempo de entre una y cuatro semanas en las que se desarrollarán determinadas historias de usuario. Cuando se define el primer sprint se colocan en una pizarra las historias de usuario, para cada historia se definirán unos test de aceptación que asegurarán una vez cumplidos que la tarea está finalizada y se colocarán pequeñas sub-tareas necesarias para la realización de la historia de usuario. La pizarra tendrá varios \emph{pools} que indicarán las sub-tareas a realizar, las que están en proceso y las que ya se han realizado. Éstas sub-tareas se irán cambiando de posición según sea su estado. La morfología de la pizarra de Scrum se muestra en la siguiente figura.

%FOTO SCRUM CATEC SIMFORPAS

Durante el sprint se hará una reunión diaria entre el equipo y el ScrumMaster en la que se hablará del estado del proyecto, qué se realizó el día anterior, qué se realizará en ese día y qué problemas han surgido para buscar entre todos soluciones y que ningún miembro del equipo se quede estancado en una tarea.

Una vez finalizado el sprint se organiza una reunión de retrospectiva, a la que acudirá el equipo, el ScrumMaster y el product owner en la que se presentará el estado del proyecto, qué es lo que se ha llevado a cabo durante el sprint, qué problemas han surgido, que se podría modificar/mejorar. El cliente dará el visto bueno y hará las peticiones que vea necesarias, se hará la gráfica de burn down para documentar el estado de esa fase del proyecto y se organizarán las tareas para el siguiente sprint.

\imgCentrada{fig.2.2}{img/scrum.eps}{Ciclo metodología Scrum.}

Esta forma de trabajo se repetirá hasta la finalización del proyecto, nos asegurará que el cliente está implicado en el desarrollo y que conocerá de antemano el producto que va a comprar y podrá interceder en su morfología. Con este método el equipo de desarrollo trabaja de una forma más relajada evitando la acumulación de trabajo a última hora y los estancamientos ya que entre el equipo debe fluir la comunicación y el problema que tenga uno en la realización de su parte se convierte en problema de todos. El cliente podrá añadir cambios o complementos al proyecto a sabiendas de que esos cambios vendrán con el sacrificio de otras historias de usuario programadas o de un incremento del tiempo de desarrollo y del coste del proyecto.

\subsection{Test Driven Development}

\lettrine{E}{l} desarrollo guiado por pruebas o TDD por sus siglas en inglés consiste en una práctica de programación que implica a su vez otras dos prácticas: Escribir las pruebas antes que el código y refactorizar. Una vez habiendo definido la funcionalidad de la parte del código que vamos a escribir hacemos un test que pruebe esa funcionalidad y una vez definido éste test y fallando nos disponemos a codificar la solución que lo resuelva, de esta forma nos aseguramos de que no perdemos ninguna función al programar el código. Si se hace al revés el test se ve afectado por la forma que tiene el código y tendemos a probar lo que sabemos que va a ocurrir dejándonos muchos casos sin resolver que pueden afectar más tarde al correcto funcionamiento de nuestro programa. Con esta técnica también nos aseguramos que en el momento en que se realice un cambio en el programa nada deja de funcionar, puesto que en todo momento el código debe pasar los test asegurando que no se pierde ninguna funcionalidad debida al nuevo cambio.

Una vez se ha escrito el test, se ha comprobado que fallaba y se ha resuelto viene la hora de refactorizar el código, como no sabemos  a priori cómo va a ser el código final debemos probablemente el código que hemos escrito para pasar ese test sea memorable, por eso tenemos que estudiar la forma correcta de escribir esa parte del código, esto se hace mediante una refactorización. Una vez realizada ésta refactorización se vuelven a pasar los test, si no pasan habría que repasar el código para que se solucione el error y luego volver a repasar la refactorización.

\imgCentradaMed{fig.2.3}{img/tdd.eps}{Ciclo TDD.}

\newpage

Mediante ésta técnica nos aseguramos un código limpio, bien estructurado y libre de errores. Otra funcionalidad de los test es explicar de qué manera se usa el código que estamos programando, ya que para probar nuestros métodos y clases debemos hacer uso de ellas, y este uso queda reflejado en el test.

\subsection{Pair programming}

\lettrine{A}{} la hora de programar es muy común perder mucho tiempo con errores al codificar así como en tomar decisiones correctas sobre qué forma darle al código, una técnica que evita estas situaciones es la programación por parejas, consiste en unir a dos desarrolladores para que programen juntos en el mismo puesto de trabajo, de forma que mientras uno programa el otro vigila que no tenga errores. También deciden entre los dos cómo hacer las cosas de una forma objetiva, siempre es bueno tener una segunda opinión y discutir cuál es la mejor solución a un problema.

A priori puede parecer que éste método hace que dos personas estén haciendo el trabajo de una, pero a la larga esto acelera el tiempo de desarrollo. También es muy útil a la hora de transmitir conocimientos a una nueva incorporación al equipo o para enseñar a programadores junior.

Cada cierto tiempo se pueden intercambiar los papeles lo que les permitirá a las dos partes coger soltura y ver el código con perspectiva de forma que puedan abstraerse y tener una visión global. Ésta técnica puede combinarse con la programación guiada por tests de forma que uno de los dos escribe el test y el otro tiene que escribir el código que lo resuelve para que el otro tenga la obligación de pensar de qué forma podría fallar y así tener una mayor cobertura frente a fallos.

\imgCentradaMed{fig.2.4}{img/pair.eps}{Pair programming.}

\section{Tecnologías}

\lettrine{A}{ntes} de iniciar el desarrollo del proyecto debemos decidir qué tecnologías son las más adecuadas a la hora de realizar ciertas tareas, como por ejemplo, unos de los requisitos para el simulador de UAV's es que las comunicaciones deben ocurrir en tiempo real, así como el procesado de datos, por tanto necesitamos un lenguaje que nos ofrezca esta velocidad como podría ser c++.

A continuación enumeraremos y daremos una breve explicación de cada una de las tecnologías usadas durante el desarrollo del proyecto SIMFORPAS.

\subsection{Programación orientada a objetos}

\lettrine{L}{a} programación orientada a objetos es un paradigma de programación en el que las funciones las realizan los \emph{objetos}. Está basado en varias técnicas como la \emph{herencia}, la \emph{cohesión}, \emph{abstracción}, \emph{polimorfismo}, \emph{acoplamiento} y \emph{encapsulamiento}. La principal característica de éste paradigma es que relaciona el sistema con el mundo real, en el que cada entidad que cumple una función está representada por un objeto en el código, así podemos encontrar objetos controladores, fábricas, etc...

La herencia y el polimorfismo son técnicas que nos permiten crear un código mucho más legible, limpio, y fácil de mantener debido al encapsulamiento de responsabilidades que hace que cuando necesitemos encontrar una función de nuestro código sepamos en qué lugar buscar y no tengamos que depurar todas las líneas como ocurre en paradigmas como la programación estructural. 

Entre las muchas ventajas de la programación orientada a objetos podemos encontrar la robustez del código debido a que una clase que no funcione correctamente no debe afectar al resto del código, es capaz de abstraer entidades del mundo real haciendo mucho más fácil manejarlas en nuestro programa, facilita el desarrollo del software y el trabajo en equipo ya que dos personas serán capaces de trabajar sobre distintas partes del código sin interferir una en el trabajo de la otra.

\subsubsection{Características de la POO}

\begin{itemize}
\item\textbf{Abstracción:} Denota las características esenciales de un objeto, donde se capturan sus comportamientos. Cada objeto en el sistema sirve como modelo de un "agente" abstracto que puede realizar trabajo, informar y cambiar su estado, y "comunicarse" con otros objetos en el sistema sin revelar cómo se implementan estas características. Los procesos, las funciones o los métodos pueden también ser abstraídos, y, cuando lo están, una variedad de técnicas son requeridas para ampliar una abstracción. El proceso de abstracción permite seleccionar las características relevantes dentro de un conjunto e identificar comportamientos comunes para definir nuevos tipos de entidades en el mundo real. La abstracción es clave en el proceso de análisis y diseño orientado a objetos, ya que mediante ella podemos llegar a armar un conjunto de clases que permitan modelar la realidad o el problema que se quiere atacar.
\item\textbf{Encapsulamiento:} Significa reunir todos los elementos que pueden considerarse pertenecientes a una misma entidad, al mismo nivel de abstracción. Esto permite aumentar la cohesión de los componentes del sistema. Algunos autores confunden este concepto con el principio de ocultación, principalmente porque se suelen emplear conjuntamente.

\item\textbf{Modularidad:} Se denomina modularidad a la propiedad que permite subdividir una aplicación en partes más pequeñas (llamadas módulos), cada una de las cuales debe ser tan independiente como sea posible de la aplicación en sí y de las restantes partes. Estos módulos se pueden compilar por separado, pero tienen conexiones con otros módulos. Al igual que la encapsulación, los lenguajes soportan la modularidad de diversas formas.
\item\textbf{Principio de ocultación:} Cada objeto está aislado del exterior, es un módulo natural, y cada tipo de objeto expone una interfaz a otros objetos que especifica cómo pueden interactuar con los objetos de la clase. El aislamiento protege a las propiedades de un objeto contra su modificación por quien no tenga derecho a acceder a ellas; solamente los propios métodos internos del objeto pueden acceder a su estado. Esto asegura que otros objetos no puedan cambiar el estado interno de un objeto de manera inesperada, eliminando efectos secundarios e interacciones inesperadas. Algunos lenguajes relajan esto, permitiendo un acceso directo a los datos internos del objeto de una manera controlada y limitando el grado de abstracción. La aplicación entera se reduce a un agregado o rompecabezas de objetos.
\item\textbf{Polimorfismo:} Comportamientos diferentes, asociados a objetos distintos, pueden compartir el mismo nombre; al llamarlos por ese nombre se utilizará el comportamiento correspondiente al objeto que se esté usando. O, dicho de otro modo, las referencias y las colecciones de objetos pueden contener objetos de diferentes tipos, y la invocación de un comportamiento en una referencia producirá el comportamiento correcto para el tipo real del objeto referenciado. Cuando esto ocurre en "tiempo de ejecución", esta última característica se llama asignación tardía o asignación dinámica. Algunos lenguajes proporcionan medios más estáticos (en "tiempo de compilación") de polimorfismo, tales como las plantillas y la sobrecarga de operadores de C++.
\item\textbf{Herencia:} Las clases no se encuentran aisladas, sino que se relacionan entre sí, formando una jerarquía de clasificación. Los objetos heredan las propiedades y el comportamiento de todas las clases a las que pertenecen. La herencia organiza y facilita el polimorfismo y el encapsulamiento, permitiendo a los objetos ser definidos y creados como tipos especializados de objetos preexistentes. Estos pueden compartir (y extender) su comportamiento sin tener que volver a implementarlo. Esto suele hacerse habitualmente agrupando los objetos en clases y estas en árboles o enrejados que reflejan un comportamiento común. Cuando un objeto hereda de más de una clase se dice que hay herencia múltiple; siendo de alta complejidad técnica por lo cual suele recurrirse a la herencia virtual para evitar la duplicación de datos.
\item\textbf{Recolección de basura:} La recolección de basura o garbage collection es la técnica por la cual el entorno de objetos se encarga de destruir automáticamente, y por tanto desvincular la memoria asociada, los objetos que hayan quedado sin ninguna referencia a ellos. Esto significa que el programador no debe preocuparse por la asignación o liberación de memoria, ya que el entorno la asignará al crear un nuevo objeto y la liberará cuando nadie lo esté usando. En la mayoría de los lenguajes híbridos que se extendieron para soportar el Paradigma de Programación Orientada a Objetos como C++ u Object Pascal, esta característica no existe y la memoria debe desasignarse expresamente.
\end{itemize}

\imgCentradaMed{fig.2.5}{img/poo.eps}{Pilares de la POO.}

La manera que usaremos para sacar el mayor partido a la programación orientada a objetos será haciendo uso de los principios \emph{S.O.L.I.D.} como guía de buenas formas a la hora de programar.

\newpage
\subsubsection{Principios S.O.L.I.D.}

\lettrine{R}{representan} cinco principios básicos del uso de la POO y del diseño software. Éstos conceptos fueron recogidos por Robert C. Martin en torno al año 2000, los principios S.O.L.I.D. son una guía que ayuda al programador a elaborar un código más limpio, legible y fácil de mantener y extender. Su uso se adapta a dos conceptos que hemos visto anteriormente como son el de TDD y Refactorización, ya que estos dos tienen como finalidad buscar un código que cumpla siempre con estas directrices.

El acrónimo S.O.L.I.D. responde a las siguientes definiciones:

\begin{itemize}
\item\textbf{S}ingle responsibility principle: El principio de única responsabilidad dice que una clase sólo debería tener una única responsabilidad, de esa forma solo tendría una única razón para cambiar y así se contiene la propagación de cualquier cambio que realicemos sobre ella sin que afecte a otra parte del código que no tiene nada que ver con dicha responsabilidad.
\item\textbf{O}pen/close principle: Nos explica la importancia de que el código esté abierto a su extensión pero cerrado a su modificación, esto nos permite modificar la funcionalidad de una clase sin necesidad de tocar su código, lo que requeriría revisiones, pruebas y comprobaciones de que todo sigue funcionando correctamente.
\item\textbf{L}iskov substitution principle: Es una definición particular de una relación de subtipificación, llamada tipificación del comportamiento, esto quiere decir que en un código puede usarse cualquier clase hija del mismo padre sin que esto altere las propiedades de ese programa.
\item\textbf{I}nterface segregation principle: Es una reflexión que apunta que es mejor tener muchas interfaces específicas a una genérica, de esta forma evitamos que el cliente haga uso de propiedades de la interfaz que no necesita o a las cuales no debería tener acceso, también es una buena herramienta de documentación de la funcionalidad del programa y así se define mejor la funcionalidad de pasa clase.
\item\textbf{D}dependency inversión principle: Éste principio apunta que las dependencias entre partes del código deben hacerse sobre abstracciones no sobre implementaciones, de esta forma una clase que haga uso de otra no dependerá del código que se haya escrito para la segunda y si en algún momento éste cambiara no afectaría a la primera. Esto ayuda a mejorar el mantenimiento del código y lo prepara para futuras modificaciones.
\end{itemize}

\newpage
\subsection{C++}

\lettrine{P}{ara} la consecución de nuestro objetivo de rapidez a la hora del procesado de datos necesitamos un lenguaje que nos ofrezca esta característica, debido a la estructura del lenguaje de programación orientado a objetos \emph{Java}, éste resulta lento y pesado a la hora de ejecutarse lo que supondría retrasos en el intercambio de datos, cosa que no nos podemos permitir cuando una aeronave depende de la comunicación que mantengamos con ella. C, al ser un lenguaje a más bajo nivel nos ofrece ésta característica, pero al ser un lenguaje estructural nos priva de la ventaja de los lenguajes orientados a objetos. Una buena combinación de estas dos características es el lenguaje C++, éste lenguaje es una extensión de C que nos permite la manipulación de objetos, desde el punto de vista de la programación orientada a objetos, éste es un lenguaje híbrido.

\imgCentradaMed{fig.2.6}{img/cpp11.eps}{Ilustración c++11.}

Debido a su base C de bajo nivel, teniendo que gestionar la memoria del programa, nos permite tener la velocidad requerida, por eso es la mejor opción para el sistema que queremos desarrollar. En 2011 se actualizó la biblioteca estándar de C++ con la nueva versión C++11, que ofrece nuevas funcionalidad para facilitar la labor del programador.

Una de las bibliotecas principales que usamos en C++ es Qt, una biblioteca multiplataforma que nos permite, entre otras funcionalidades, crear aplicaciones con interfaz gráfica, el API de la biblioteca también cuenta con métodos para acceder a bases de datos, uso de XML, gestión de hilos y otras muchas funciones útiles a la hora de programar.

Éste lenguaje lo usaremos a la hora de realizar las funciones de simulación y comunicación entre los diferentes módulos del sistema, en el siguiente capítulo haremos hincapié en qué función requerirá el uso de éste lenguaje.

\newpage
\subsection{Java}

\lettrine{E}{l} proyecto podría dividirse en tres partes bien identificadas, por un lado tenemos el simulador de la aeronave, la GCS y el puesto de instructor, los dos primeros como ya hemos explicado requieren una respuesta rápida ya que el vuelo simulado depende de la rapidez en las comunicaciones y para asegurar que el entorno es similar a un vuelo en la vida real necesitamos tratar al simulador como si fuera una aeronave real.

Sin embargo el puesto de instructor no requiere una interacción con el sistema que sea en tiempo real, sino que importa más que la aplicación, al estar separada del resto de módulos, sea multi-plataforma para abstraernos del entorno desde el que se use y sea fácilmente portable, así como que disponga de un método de comunicación compatible con el resto del sistema. Java es un lenguaje totalmente orientado a objetos, se ejecuta sobre una máquina virtual (JVM) adaptada a la mayoría de sistemas operativos, lo que convierte cualquier aplicación java en multi-plataforma. 

\imgCentradaMed{fig.2.7}{img/java.eps}{Logo Java.}

Al ser un lenguaje orientado a objetos nos da todas las facilidades que ya explicamos antes y debido a la gran comunidad y a lo extendido que está éste lenguaje de programación tenemos un número infinito de herramientas y tecnologías que se pueden implementar con Java, incluido el método de comunicación entre módulos que usaremos para el intercambio de información que usaremos en el proyecto, por tanto es el lenguaje perfecto para lo que necesitamos. También permite la implementación de páginas web de manera rápida y sencilla lo que nos permitirá darle aún más accesibilidad a la aplicación ya que podría instalarse en un servidor y accederse desde cualquier terminal conectado a él.

\subsection{Patrones de diseño}

\lettrine{A}{} la hora de programar solemos encontrarnos una gran cantidad de veces con problemas recurrentes de diseño de cuya solución puede depender que nuestro código se alivie o que salga herido. Una mala solución a un problema normalmente acarreará más cambios en el resto del código, en cuanto al diseño del software hay una serie de problemas que son bastante conocidos ya que suelen aparecer frecuentemente, por ejemplo, tenemos que implementar una aplicación que trabaja con una base de datos y una interfaz de usuario gestionada por una clase que se comunica directamente con la base de datos y la interfaz representando estos datos. Si en algún momento se quisiera modificar cualquiera de las partes, base de datos, interfaz o añadir una nuevo funcionalidad o modificar una ya existente este cambio afectaría al conjunto de las partes y prácticamente tendríamos que reescribir parte del código sino el código entero. Para resolver este problema tenemos uno de los patrones de diseño más comunes, el patrón MVC(Modelo Vista Controlador) el cual separa la parte de persistencia de datos o modelo de datos de la interfaz del usuario, el controlador hace de puente entre los dos anteriores y guarda la lógica de negocio asociada a esos datos. La vista es la interfaz con el usuario, el modelo guarda los datos con los que se trabaja y el controlador modifica esos datos.

\imgCentradaMed{fig.2.8}{img/mvc.eps}{Diagrama MVC.}

\newpage
En 1990 el grupo \emph{Gang of Four} publica el libro \emph{Design Patterns}, en el que recogen los 23 patrones de diseño más comunes, en éste libro se recogen una serie de soluciones a problemas habituales en el diseño software. Los problemas que resuelven estos patrones de diseño han sido ampliamente estudiados por lo que podemos asegurarnos de que su uso va a ofrecernos una solución limpia y en la mayoría de los casos óptima sin necesidad de tener que reintentar la rueda. El uso compulsivo de patrones de diseño, sin embargo, es desaconsejable, los patrones son una gran ayuda en los casos en los que necesitamos de ellos, pero retorcer el código con la finalidad de introducir un patrón de diseño para resolver un problema que no necesitaba de ese patrón también podría ser negativo para nuestro programa.

\subsection{Bibliotecas}

\lettrine{C}{uando} nos enfrentamos al desarrollo de un sistema complejo que requiera el uso de muchas tecnologías disponemos de herramientas para facilitarnos el trabajo, por ejemplo, una parte importante en el desarrollo de videojuegos es el aspecto gráfico, si deseamos animar una imagen podríamos crearnos un programa que recoja las imágenes que queramos mostrar y crearnos un sistema que secuencie la muestra de estos dibujos creando así la animación, también podríamos implementar un sistema que gestione la física de nuestro juego, esto requeriría que diseñáramos desde cero un motor de juego que nos permita más adelante desarrollar nuestra aplicación. Otra opción es hacer uso de bibliotecas que nos den éstas herramientas ya desarrolladas que nos permitirá, por ejemplo, mediante el archivo que guarda las imágenes y una velocidad de animación que la biblioteca usará para automáticamente gestionar la animación de una forma transparente al programador. Otro ejemplo más sencillo es el de operaciones matemáticas incluidas en la mayoría de bibliotecas estándares de casi todos los lenguajes de programación que nos quitan el peso de tener que implementar ciertas acciones que son muy comunes, si ya está hecho y probada su calidad y buen funcionamiento no es necesario hacerlo otra vez.

Existen bibliotecas específicas para un gran número de utilidades, como por ejemplo la biblioteca \emph{Spring} de Java que nos permite gestionar fácilmente la \emph{inversión de control} en nuestro programa, de ésta biblioteca hablaremos más adelante. También existen bibliotecas que nos permiten acceder a ciertos recursos gráficos, trabajar con mapas, gestionar servicios web, hacer uso de determinadas aplicaciones, dar servicios de comunicación, etcétera...

\newpage
\subsection{Ubuntu 12.04}

\lettrine{E}{n} la búsqueda de un entorno de desarrollo que respondiese a nuestras necesidades debíamos buscar un sistema operativo que fuera estable y que nos diera libertad de configuración. El sistema que vamos a desarrollar requiere de un gran número de componentes ya sean bibliotecas o módulos adicionales, los cuales pueden inducir al sistema operativo a múltiples errores durante el desarrollo, si no disponemos de un sistema estable esto afectaría a la velocidad del desarrollo y al estado de ánimo del programador. También nos permite manipular la totalidad del sistema de forma que podemos adaptarlo al desarrollo de la forma que mejor nos convenga, sin contar la gran comunidad que tiene detrás al ser un sistema operativo de código libre lo cuál es un motivo para muchos programadores para implementar sus herramientas con compatibilidad para este sistema operativo lo que se convierte en una gran batería de herramientas a nuestro alcance a la hora de desarrollar un proyecto.

\imgCentradaPeq{fig.2.9}{img/ubuntu.eps}{Logo Ubuntu.}

\newpage
\subsection{Qt Creator}

\lettrine{P}{ara} el código del simulador que como ya explicamos anteriormente hace uso de C++ ya que nos proporciona la velocidad y robustez que necesitamos en técnicas de simulación en tiempo real hemos elegido Qt Creator como entorno de desarrollo integrado. Comenzamos usando \emph{Eclipse for C/C++} pero a la hora de realizar la integración con \emph{CMake}, del cual hablaremos más adelante, surgían muchos problemas y la velocidad de compilación era muy reducida, después de ser aconsejados por una compañera de trabajo decidimos cambiar a Qt Creator, el cual ofrece un entorno de desarrollo para C++ orientado a facilitar el uso de la biblioteca Qt de C++ y con muy buena integración con CMake. Al no depender de la máquina virtual de java la velocidad también aumentó, la interfaz es mucho más reducida que la de Eclipse y más sencilla e intuitiva aportando todas las opciones de configuración que necesitábamos.

También nos provee de una herramienta de diseño de interfaces de usuario con Qt sencilla y un debugger visual. Por todos esos motivos decidimos seguir el desarrollo con éste IDE en el caso de la programación en C++ ya que aumentó el rendimiento y redujo los fallos derivados del manejo del entorno de desarrollo. 

\imgCentradaPeq{fig.2.10}{img/qtcreator.eps}{Logo Qt Creator.}

\newpage
\subsection{Eclipse}

\lettrine{E}{l} puesto de instructor está escrito en código Java ya que necesitábamos que fuera multiplataforma, para éste lenguaje de programación, el IDE más extendido es el de la propine empresa que lo diseñó, Sun Microsystems, cuyo nombre es Eclipse. Es un programa compuesto por un conjunto de herramientas de código abierto y multiplataforma orientado al desarrollo de entornos de desarrollo integrados, en nuestro caso, lo usaremos como entorno para programadores Java ya que tiene una gran integración con herramientas necesarias en nuestro proyecto como pueden ser \emph{Maven}, \emph{Junit}, Control de versiones, etcétera... Decidimos hacer uso de él debido al gran número de herramientas de soporte para el desarrollo Java.

\imgCentradaPeq{fig.2.11}{img/eclipse.eps}{Logo Eclipse.}

\subsection{Control de versiones}

\lettrine{C}{usando} nos disponemos a afrontar un proyecto software uno de los miedos más comunes es el de tener un código que funciona bien, realizar algún cambio y que todo deje de funcionar y haya que volver a repetir el trabajo ya realizado anteriormente. Éste miedo está ampliamente superado gracias al control de versiones. Ésta técnica nos permite hacer copias de seguridad periódicas de nuestro código en un repositorio externo, de forma que si en algún momento ocurre un accidente que haga que perdamos nuestro código dispongamos de un archivo con todas las versiones anteriores de nuestro programa pudiendo volver a un punto del tiempo en el que nuestro código funcionaba correctamente, evitando así tener que repetir la solución que ya teníamos implementada.

Otro problema muy normal entre los equipos de desarrollo se presenta cuando varios integrantes necesitan tocar el mismo código, sin el control de versiones, dos personas que estén implementando sobre el mismo fichero, sin saber qué está yaciendo el otro tendrán que unir, una vez finalizados sus respectivos cambios, los dos archivos en uno único en el que convivan las modificaciones que haya hecho cada uno, esto es un trabajo bastante tedioso y problemático ya que en muchas ocasiones el código de uno se verá afectado por el de otro, de manera que cuando el segundo vuelva a revisar su código se encuentre que lo que ya funcionaba ahora no realiza correctamente su función y se le presente una dura tarea de debug para averiguar qué cambios han afectado a su código. El control de versiones nos permite crear varias ramas de desarrollo, de forma que cada programador trabaja en su rama y solo debe unir sus cambios al repositorio cuando se haya bajado el código actual, haya comprobado que no hay con conflictos entre el código principal y el suyo y su  código esté probado y funcionando correctamente, de esta forma siempre tendremos una versión del código que funciona correctamente y eliminaremos la situación en que el código escrito por dos personas sobre el mismo fichero se vea en conflicto. Éstos motivos la convierten en una técnica indispensable a la hora de organizar un equipo de desarrollo software.

Los sistemas de control de versiones pueden ser clasificados según la arquitectura que utilizan para el almacenamiento del código:

\begin{itemize}
\item\textbf{Centralizados:} Hay un único repositorio que almacena todo el código y es gestionado por un administrador o grupo de administradores. Es más sencillo de gestionar ya que para realizar algún cambio como la creación de una nueva rama hay que pedir la aprobación del responsable del repositorio. Algunos ejemplos de repositorios de éste tipo son \emph{Subversion} o \emph{CVS}.
\item\textbf{Distribuidos:} A diferencia de los anteriores, cada usuario tiene su propia copia del repositorio. Los distintos repositorios pueden intercambiar y mezclar revisiones entre ellos. Existe también un repositorio principal que sirve para sincronizar el resto de repositorios locales. Entre los repositorios de éste tipo podemos encontrarnos \emph{Mercurial} o \emph{Git}.
\end{itemize}

Ventajas de los sistemas distribuídos:

\begin{itemize}
\item Necesita menos veces estar conectado a la red para hacer operaciones. Esto produce una mayor autonomía y una mayor rapidez.
\item Aunque se caiga el repositorio remoto la gente puede seguir trabajando.
\item Al hacer los distintos repositorio una réplica local de la información de los repositorios remotos a los que se conectan, la información está muy replicada y por tanto el sistema tiene menos problemas en recuperarse si por ejemplo se quema la máquina que tiene el repositorio remoto. Por tanto hay menos necesidad de backups.
\item Permite mantener repositorios centrales más limpios en el sentido de que un usuario puede decidir que ciertos cambios realizados por él en el repositorio local, no son relevantes para el resto de usuarios y por tanto no permite que esa información sea accesible de forma pública. Por ejemplo es muy útil se pueden tener versiones inestables o en proceso de codificación o también tags propios del usuario.
\item El servidor remoto requiere menos recursos que los que necesitaría un servidor centralizado ya que gran parte del trabajo lo realizan los repositorios locales.
\item Al ser los sistemas distribuidos más recientes que los sistemas centralizados, y al tener más flexibilidad por tener un repositorio local y otro/s remotos, estos sistemas han sido diseñados para hacer fácil el uso de ramas (creación, evolución y fusión) y poder aprovechar al máximo su potencial. Por ejemplo se pueden crear ramas en el repositorio remoto para corregir errores o crear funcionalidades nuevas. 
\end{itemize}

Para implementar ésta técnica en el proyecto SIMFORPAS decidimos hacer uso de las siguientes herramientas.

\subsubsection{Mercurial}

Haremos uso de un sistema de control de versiones distribuido, ya que su arquitectura de adecua mejor a nuestras necesidades como equipo de desarrollo. Usaremos Mercurial un sistema de control de versiones distribuido multiplataforma, originalmente escrito para trabajar en sistemas Linux como Ubuntu. Es un programa para línea de comandos y ofrece un protocolo de acceso mediante red muy eficiente que persigue reducir el tamaño de los datos así como la gestión de múltiples peticiones y conexiones. Su código se distribuye bajo licencia GNU GPL, lo que lo clasifica como Software Libre.

\imgCentradaPeq{fig.2.12}{img/mercurial.eps}{Logo Mercurial.}

\newpage
\subsubsection{Bitbucket}

Bitbucket es un servicio web de alojamiento de código que use sistema de control de versiones Mercurial y Git. Ofrece alojamiento gratuito u opcional de pago, permitiendo éste segundo un mayor número de participantes en el repositorio. También nos da la opción de crear repositorios tanto públicos como privados y el manejo de funciones propias de Mercurial como la creación de \emph{Forks} que nos permitan clocar un repositorio en un punto determinado y desarrollar en él, mientras el administrador se encarga de gestionar la adición de los cambios que aporte ese foro al repositorio principal, asegurando que el código principal siempre va a gozar de buena salud.

\imgCentradaPeq{fig.2.13}{img/bitbucket.eps}{Logo Bitbucket.}

\subsubsection{TortoiseHg}

Es un cliente de escritorio para Ubuntu de control de versiones Mercurial que nos permite interactuar entre los archivos locales de nuestro código y el repositorio remoto, de forma que nos gestiona nuestro repositorio local y nos permite tenerlo sincronizado con el remoto comprobando si ha habido cambios, pudiendo actualizar nuestro repositorio, el remoto y todas las funciones características del control de versiones como los push, pull, así como una herramienta de solución de conflictos en el código.

\newpage
\subsection{Pruebas unitarias}

\lettrine{E}{l} código escrito por un programador está siempre sujeto a errores inherentes a la condición humana, por éste motivo siempre debemos probar un código después de haberlo implementado. Si tratásemos de probar el código después de haber acabado un proyecto completo seguramente nos encontraríamos con una gran cantidad de fallos difícilmente localizables y requeriría mucho tiempo descubrir qué es lo que funciona mal y cuál es su solución. Una buena técnica para evitar esto es realizar pruebas al código parte a parte, otorgándole a cada clase su propia prueba de forma unitaria,
 
 Entre las ventajas del uso de las pruebas unitarias se encuentran:
 
 \paragraph{Encuentra problemas a tiempo:} En TDD, como ya explicamos anteriormente, se intenta definir primero la funcionalidad de una clase escribiendo la condición que tiene que cumplir para que su funcionamiento se de por bueno a través de una prueba unitaria, de esta forma tendremos conocimiento de cuando falla el código inmediatamente después de haberlo escrito. Por tanto, las pruebas unitarias alertan a los desarrolladores de un problema antes de que el producto salga al mercado.
 \paragraph{Facilita los cambios:} Las pruebas unitarias permiten al programador realizar refactorizaciones comprobando que cada parte individual del código sigue cumpliendo su función. El procedimiento requiere que se escriban pruebas para cada método del programa por lo que cualquier lugar en el que haya ocurrido un error será rápidamente reconocible ya que la prueba nos indicará dónde se ha producido el fallo.
 \paragraph{Simplifica la integración:} Ayudan a la integración entre diferentes unidades del sistema haciendo más sencillas las pruebas de varias clases en conjunto ya que cuando se vayan a hacer estas no tenemos que probar los fallos referentes al funcionamiento individual de las clases. En las pruebas unitarias de una clase no debe intervenir ninguna otra, esas casuísticas se tratan en las pruebas de integración.
 \paragraph{Aporta documentación:} Las pruebas aportan documentación práctica sobre el código ya que para implementarlos hemos tenido que utilizar esas clases de forma correcta y queda plasmada en ellos cómo quiere el desarrollado que se use esa clase, de forma que cualquiera que quiera usar ese código o conocer su funcionamiento puede acudir a las pruebas para ver de primera mano qué están haciendo esas clases.
 \paragraph{Mejora el diseño:} Cuando el software es desarrollado con guiado mediante pruebas, la combinación entre escribir los test pare definir las interfaces con la refactorización del código después de que se valide la prueba correctamente hace que la estructura del código adquiera una forma adecuada y optimizada mejorando así la calidad del mismo y favoreciendo las futuras modificaciones.
 
 \subsubsection{Google Test}
 
 Para la gestión de las pruebas unitarias en los proyectos que estén escritos en el lenguaje de programación C++ usaremos la biblioteca de pruebas de Google \emph{Google Test}. Ésta librería nos ofrece una amplia gama de herramientas para probar nuestro código, dándonos la oportunidad de ejecutar los test por separados o todos a la vez, lo que hace que cubra las necesidades de un amplio espectro de perfiles de desarrolladores.
 
 Google test funciona separando cada test de manera que unos no interfieran sobre la ejecución de los demás lo que nos proporciona fiabilidad y robustez en nuestras pruebas. También ejecuta todas las pruebas definidas en el proyecto de manera que no necesitamos listarlas de manera especial para indicarle qué test tenemos. Otra característica es la búsqueda de ofrecer el mayor número de información sobre el código que se está probando de manera que no para en el primer error que encuentra sino que sigue con las siguientes pruebas para darnos una visión más global del estado de nuestro proyecto. También nos permite reutilizar y compartir código e instancias de objetos entre los diferentes tests, que gestionamos con los \emph{set-ups} y \emph{tear-downs} de manera que los tests serán más rápidos.
 
 \subsubsection{JUnit}
 
 En cuanto a la parte del proyecto realizada en código Java haremos uso de las muy extendidas bibliotecas de pruebas para Java \emph{JUnit}. Son un conjunto de clases que nos permiten realizar la ejecución de clases Java de manera controlada para poder evaluar si el funcionamiento de los métodos de la clase se comporta como se espera. Es decir, en función de algún valor de entrada se evalúa el valor de retorno esperado, al igual que la biblioteca de pruebas para C++.
 
 Existe integración para Eclipse de JUnit, el cual puede ser obtenido a través del \emph{Market Place} incluido en el mismo programa, el cual nos ofrece un entorno gráfico para la visualización de los resultados de las pruebas. Los tests se definen mediante anotaciones, una técnica muy usada en Java que nos permite añadir metadatos al código fuente para la aplicación en tiempo de ejecución de matera que nos libera de tener que usar una biblioteca y añadir más líneas a nuestro código.
 
\subsection{Mocks}

\lettrine{L}{as} pruebas unitarias requieren que solamente se valide una única clase de forma que no afecte a la prueba ninguna otra. Pero en múltiples ocasiones nos encontramos con que la clase que queremos someter a pruebas depende de una clase externa y su funcionamiento está ligado a la interacción con esta otra clase. Para solucionar esta paradoja se nos ofrece una herramienta como son los objetos \emph{Mock}, estos objetos tienen la función de comportarse como una imitación de la clase real. Si por ejemplo necesitamos hacer uso de un método que realiza la multiplicación entre dos números y cuyo resultado usaremos para realizar alguna acción en la clase que estamos probando, la implementación de estas clase multiplicación nos ofrecerá un método que nos devuelva un número, no nos interesa que realice ninguna operación sino que nos devuelva lo que necesitamos para ejecutar nuestro código. Si usáramos la clase real estaríamos condicionados a suponer el buen funcionamiento de esta clase, de esta forma, no dependemos de ninguna forma de la clase, sino que nos ceñiremos a probar que la clase que estamos probando funciona correctamente. El si las clases de las que dependemos funcionan bien o no será responsabilidad de los test de esas clases respectivamente.

\subsubsection{GMock}

Al igual que con los entornos de pruebas unitarias, tenemos bibliotecas que nos ayudan con la generación de objetos mock para que no tengamos que preocuparnos de generar todas estas clases adicionales nosotros mismos. Para pruebas unitarias con Google Test usaremos \emph{GMock}, una biblioteca de Google que nos permite generar este tipo de objetos rápidamente, de manera sencilla y con una amplia gana de configuraciones entre las que podemos probar el número de veces que se espera llamar a ése método y qué objeto queremos que devuelva en cada una de las llamadas así como definir con qué parámetros de entrada se debe invocar, todo esto integrado con el entorno de pruebas de Google Test. Existe una amplia documentación sobre ésta tecnología incluido el \emph{CookBook para GMock} de Google donde se explican detalladamente y con ejemplos cada una de las características de esta biblioteca.


\subsubsection{JMock}

Para JUnit también tenemos una biblioteca similar que es \emph{jMock}, jMock nos ofrece las mismas características que ya explicamos anteriormente con GMock, tiene integración con JUnit y al estar diseñado con anotaciones también permite que nuestro código quede más limpio, rápido y sea más fácil de usar. Nos permite especificar que tipo de interacción existe entre nuestros objetos reduciendo la fragilidad de nuestro código.

\subsection{CMake}

\lettrine{C}{Make} es una familia de herramientas diseñada para construir, probar y empaquetar software. \emph{CMake} se utiliza para controlar el proceso de compilación del software usando ficheros de configuración sencillos e independientes de la plataforma. El proceso de construcción se controla creando uno o más ficheros CMakeLists.txt en cada directorio (incluyendo subdirectorios). Cada CMakeLists.txt consiste en uno o más comandos. Cada comando tiene la forma COMANDO (argumentos...) donde COMANDO es el nombre del comando, y argumentos es una lista de argumentos separados por espacios. CMake provee comandos predefinidos y definidos por el usuario. Entre las principales funcionalidades CMake nos ofrece un análisis automático de dependencias. 

Debido a que en nuestro proyecto hacemos uso de subproyectos de configuración similar como pueden ser el núcleo del simulador, la primera versión del proyecto que gestiona el modelo, etc... CMake nos aporta una gran ayuda a la hora de iniciar un nuevo proyecto con características similares a alguno que ya hayamos creado ya que la configuración la gestiona CMake y no tenemos que preocuparnos de configurar las dependencias ni otros tipos de configuraciones.

Ejemplo de CMakeLists.txt

\imgCentrada{fig.2.14}{img/cmakelists.eps}{Ejemplo CMakeLists.txt.}

\newpage
\subsection{Maven}

\lettrine{M}{aven}, al igual que CMake, es una herramienta software para la creación de proyectos, en este caso para proyectos Java con un modelo de configuración muy simple basado en \emph{XML}. Maven utiliza un Project Object Model(POM) para describir el proyecto de software a construir, sus dependencias de otros módulos y componentes externos, y el orden de construcción de los elementos. Viene con objetivos predefinidos para realizar ciertas tareas claramente definidas, como la compilación del código y su empaquetado. Una característica clave de Maven es que está listo para usar en red. El motor incluido en su núcleo puede dinámicamente descargar plugins de un repositorio, el mismo repositorio que provee acceso a muchas versiones de diferentes proyectos Open Source en Java, de Apache y otras organizaciones y desarrolladores. Maven provee soporte no sólo para obtener archivos de su repositorio, sino también para subir artefactos al repositorio al final de la construcción de la aplicación, dejándola al acceso de todos los usuarios. Una caché local de artefactos actúa como la primera fuente para sincronizar la salida de los proyectos a un sistema local.

Otra aplicación interesante de Maven es la posibilidad de crear \emph{arquetipos}. Los arquetipos se pueden considerar como plantillas de configuración para un nuevo proyecto, de forma que una vez configurado nuestro proyecto con Maven podemos guardar esas características, librerías usadas, estructura del proyecto, etc... y guardarla de manera que podamos usarla para la generación de un proyecto de características similares.

A la hora de programar el puesto de instructor necesitaremos que sea una aplicación web y aprovechar las múltiples bibliotecas de utilidad que nos ofrece Java como Spring, Struts, Hibernate, etc... Para gestionar todas estas configuraciones necesarias haremos uso de Maven.
\newpage
Ejemplo de POM.xml

\imgCentradaMed{fig.2.15}{img/pom.eps}{Ejemplo POM.xml.}
\newpage
\subsection{ANIMO DDS}

\lettrine{P}{ara} solucionar el problema de intercambio de datos entre los distintos módulos que compondrán nuestro sistema usaremos un midleware de comunicaciones basado en DDS RTI (Data DIstribution Service de la compañía Real Time Innovations), una tecnología que nos permite conectar varios sistemas entre sí de forma distribuida, de esta forma disponemos de un medio de intercambio de información sencillo, escalable y sin necesidad de preocuparnos de conectividad a bajo nivel. El uso de DDS RTI también nos garantiza que las comunicaciones se realizarán en tiempo real y sin perder ningún dato, una funcionalidad indispensable cuando estamos trabajando con dispositivos críticos como los UAV en los que cualquier pérdida de algún dato puede introducir fallos en el sistema. Al estar basado en el patrón publicador-subscriptor y nuestro entorno estar estructurado en módulos podemos ampliar la funcionalidad como queramos sin necesidad de afectar al resto de módulos. Por ejemplo, si la aeronave está publicando su posición podemos crear una aplicación de monitorización que se subscriba a este dato sin afectar al resto de componentes.

ANIMO es un framework envoltura de DDS RTI que nos ofrece una serie de herramientas que facilitan el uso de estas librerías ya que simplifica muchas de las configuraciones previas necesarias para realizar una comunicación DDS, también permite mediante un sencillo archivo de configuración crear los archivos necesarios para un nuevo tipo de dato automáticamente mediante un generador de códigos. Gracias a las calidades de servicio de DDS RTI podemos definir muchas variables en la comunicación de los datos, desde enviar un primer dato cuando se inicie la comunicación para un cierto tipo con el fin de comprobar que todo funciona bien hasta decidir el tiempo que tiene que pasar para que un dato se de por perdido o incluso establecer un identificador para el destinatario, de esta forma nos aseguramos que la comunicación es fiable y segura.

\imgCentradaMed{fig.2.16}{img/rti.eps}{Logo de RTI.}

\newpage
\subsection{Spring}
\lettrine{E}{n} la realización de nuestro proyecto usaremos un patrón de diseño muy extendido sobre la programación orientada a objetos que es la \emph{Inyección de dependencias}, este patrón consiste en suministrar objetos a una clase en lugar de que sea esa clase la que los crea. De esta forma se controla mejor el acceso a los componentes y no tenemos que encapsular objetos dentro de otros objetos para mantener el acceso de forma que se nos ensucie el código y se ponga en riesgo su legibilidad y escalabilidad. En lugar de eso una clase es la encargada de hacer de contenedor de todos los objetos necesarios durante la ejecución del programa y desde esa clase se tomaran las instancias que se pasarán como parámetros de entrada de los constructores de las clases que hagan uso de ellos.

Para implementar este patrón usaremos el framework open source Spring que nos provee una serie de librerías para Java para controlar de forma sencilla la inyección de dependencias en nuestra aplicación. Debido al éxito y las múltiples ampliaciones que ha tenido Spring, éste también nos provee de otras herramientas útiles a la hora de programar como un módulo de acceso a datos para trabajar con bases de datos relacionales y no relacionales, un módulo de aplicación del modelo vista controlador, un módulo de testing, etcétera...

Spring nos ofrece varias alternativas a la hora de configurar la creación de objetos o \emph{beans}, un ase ellas es mediante un archivo XML donde se define la ruta a las clases que van a ser beans y donde se indica cuantos jeans se van a crear. Otra forma es mediante el uso de \emph{anotaciones}, definiendo directamente una anotación en el código de la clase podemos controlar más fácilmente el uso de estos beans.

\subsubsection{Ventajas de la Inyección de Dependencias}

\paragraph{Se reduce el código pegamento: }esto quiere decir que se reduce dr?asti- camente la cantidad de c?odigo que se debe escribir para unir los distintos componentes una aplicaci?on, proporcionando bu?squedas autom?aticas para instanciar objetos remotos.

\paragraph{Se externalizan dependencias: }al ser posible colocar la configuración de dependencias en archivos gXML, se puede realizar una reconfiguración fácilmente, sin necesidad de recompilar el código. De la misma forma, es posible realizar el cambio de la implementación de una dependencia a otra.

\paragraph{Las dependencias se manejan en un solo lugar: }toda la información de dependencias es responsabilidad de un sólo componente, el Contenedor de IoC de Spring, proporcionando un manejo de dependencias m?as simple y menos propenso a errores.

\paragraph{Hace que las pruebas sean más fáciles: }como las clases serán diseñadas para hacer fácil el reemplazo de dependencias, se podrán proporcionar objetos simulados que regresen datos de prueba, de servicios o cualquier dependencia que necesite el componente que estamos probando.

\subsubsection{Módulos de Spring}

\paragraph{IoC Container: }los componentes no crean, o buscan las referencias a otros componentes que necesiten para realizar su trabajo, sino que simplemente declaran qué dependencias tienen, y el contenedor para la Inversión de Control les proporciona automáticamente estas dependencias.

\paragraph{Acceso a Datos / Integración: }en este grupo, Spring mapea las SQLException a excepciones específicas y automatiza la gestión de conexiones. Se declara una fuente de datos y Spring la gestiona.

\paragraph{WEB: }En este grupo se encuentran las herramientas para implementar el Patrón de DiseñoModelo Vista Controlador y el acceso a componentes remotos. Esto facilita el desarrollo de aplicaciones distribuidas y reduce el código que se necesita para exponer un bean como servicio o para acceder desde un bean a un servicio remoto. También unifica distintas A.P.I. para la gestión de transacciones.

\paragraph{Programación Orientada a Aspectos: }Permite combinar cierto código con otro para añadir cierta funcionalidad al original sin necesidad de modificarlo, facilitando así la implementación de funcionalidades transversales de una aplicación.

\imgCentradaMed{fig.2.17}{img/spring.eps}{Logo Spring.}

\newpage
\subsection{Struts 2}

\lettrine{Y}{a} introdujimos anteriormente el modelo vista controlador o MVC y los beneficios de usarlo en nuestra aplicación. Para su implementación se hará uso de Struts 2, una herramienta de soporte para el desarrollo de aplicaciones web en Java de la compañía Apache. Es de código abierto y nos permite simplificar la conexión entre nuestro código java y la parte de la vista web de la aplicación.

El núcleo de Struts es un filtro conocido como \emph{FilterDispatcher} el cual nos permite ejecutar los \emph{actions} que son los métodos lanzados por peticiones web, comenzar la ejecución de interceptores y gestionar la memoria para evitar fugas.

Las peticiones se procesan usando tres elementos principales: Interceptors, Actions y Results.

\subsubsection{Interceptors}

Los Interceptores son clases que siguen el Patrón de Diseño Interceptor. Estos permiten que se implementen funcionalidades cruzadas o comunes para todos los Actions, pero que se ejecuten fuera del Action (por ejemplo validaciones de datos, conversiones de tipos, población de datos, etc).

Éstos realizan tareas antes y después de la ejecución de un Action y también pueden evitar que un Action se ejecute (por ejemplo si se está haciendo alguna validación que no se ha cumplido).También sirven para ejecutar algún proceso particular que se quiere aplicar a un conjunto de Actions. De hecho muchas de las características con que cuenta Struts2 son proporcionadas por los Interceptors.
Si alguna funcionalidad que necesitamos no se encuentra en los Interceptores de Struts2 podemos crear nuestro propio Interceptor y agregarlo a la cadena que se ejecuta por defecto. De la misma forma, podemos modificar la cadena de Interceptor de Struts2, por ejemplo para quitar un Interceptor o modificar su orden de ejecución.

Cada Interceptor proporciona una característica distinta al Action. Para sacar la mayor ventaja posible de los Interceptors, un Action permite que se aplique m?as de un Interceptor. Para lograr esto Struts2 permite crear pilas o stacks de Interceptors y aplicarlas a los Actions. Cada Interceptor es aplicado en el orden en el que aparece en la pila. También podemos formar pilas de Interceptors en base a otras pilas.

\subsubsection{Actions}

Las Acciones o Actions son clases encargadas de realizar la lógica para servir una petición. Cada URL es mapeada a una Action específica, la cual proporciona la lógica necesaria para servir a cada petición hecha por el usuario. Estrictamente hablando, las Actions no necesitan implementar una interfaz o extender de alguna clase base. El único requisito para que una clase sea considerada un Action es que debe tener un método que no reciba argumentos y que devuelva un objeto String o un objeto de tipo Result. Por defecto el nombre de este método debe ser execute aunque podemos ponerle el nombre que queramos y posteriormente indicarlo en el archivo de configuración de Struts2.
Cuando el resultado es un String, el objeto tipo Result correspondiente se obtiene de la configuración del Action. Esto se usa para generar una respuesta para el usuario.
Los Actions pueden ser P.O.J.O.s que cumplan con el requisito anterior, aunque por lo general, también pueden implementar la Interfaz com.opensymphony. xwork2.Action o extender una clase base que proporciona Struts2: com.opensymphony. xwork2.ActionSupport, lo cual hace más sencilla su creación y manejo.
La clase ActionSupport implementa la interfaz Action y contiene una implementación del método execute() que devuelve el valor SUCCESS. Además proporciona unos cuantos métodos para establecer mensajes, tanto de error como informativos, que pueden ser mostrados al usuario.

\subsubsection{Results}

Después de que un Action haya sido procesado, se debe enviar la respuesta de regreso al usuario, esto se realiza usando Results. Este proceso tiene dos componentes, el tipo del objeto Result y el resultado mismo.
El tipo del Result indica cómo debe ser tratado el resultado que se le devolver?a al cliente. Por ejemplo un tipo de Result puede enviar al usuario de vuelta un objeto JSP mientras que otro puede redirigirlo hacia otro sitio.
Un Action puede tener m?as de un objeto tipo Result asociado. Esto nos permitirá enviar al usuario a una Vista distinta dependiendo del resultado de la ejecución del Action. Por ejemplo, en caso de que todo salga bien, enviaremos al usuario al objeto tipo Result sucess, si algo sale mal lo enviaremos al objeto tipo Result error, o si no tiene permisos lo enviaremos al objeto tipo Result denied.

\imgCentradaMed{fig.2.18}{img/struts2.eps}{Logo Struts 2.}

Para evitar tener que realizar la configuración de Struts mediante el archivo XML, usaremos un plugin de Apache para Struts llamado \emph{Convention Plugin} el cual nos ofrece una forma sencilla de determinar en el mismo código como realizar las conexiones entre vistas y modelos. Usando la nomenclatura de las clases que creemos podemos determinar que parte del modelo se lanzará cuando se haga una llamada desde la vista. Así si por ejemplo tenemos una acción llamada NuestraAction.java, cuando cargamos la url con nombre nuestra-action.jsp se hará una llamada a la acción del mismo nombre, así podemos controlar las conexiones sin necesidad de usar ni archivos de configuración ni anotaciones.

\newpage
\subsection{Hibernate}

\lettrine{E}{n} vistas de la futura necesidad de almacenar datos de forma persistente, ya sean misiones a realizar por un alumno, log de misiones realizadas, calificaciones, datos de alumnos, modelos de distintos UAVS, etcétera, implementaremos un sistema que nos permitan trabajar con bases de datos de forma sencilla y escalable. Para ello requeriremos de un sistema que nos permita hacer una implementación del patrón de diseño \emph{DAO} o Data Access Object. Al diseñar una base de datos de forma tradicional necesitamos adaptar nuestro código a los datos que vayan a guardarse en esa base de datos, y dependeremos de la forma en que estén guardados, el tipo de base de datos y cómo se nos presenta esos datos de manera que si en algún momento se cambia algo en la base de datos será muy complicado reutilizar el código que teníamos y necesitaremos realizar muchos cambios para adaptar la nueva base de datos.

Para evitar esto disponemos del patrón DAO el cual consiste en disponer de unos objetos que nos hagan de puente entre nuestro programa y la base de datos, estos objetos se encargarán de realizar las conexiones con la base de datos y crear a partir de la petición que hagamos a esa base de datos de alguna entidad el objeto java que usaremos en la ejecución. Si en algún momento necesitamos modificar la base de datos solo tendríamos que cambiar estos objetos por unos que se adecuen a los nuevos requerimientos de forma que no afecta al resto de la aplicación.

Para implementar esta solución usaremos Hibernate en su versión 4.3.4, Hibernate es una herramienta de mapeo objeto-relacional para la plataforma Java, mediante anotaciones sobre las clases que queremos guardar en la base de datos podemos autogenerar los objetos DAO e incluso crear las tablas en la base de datos, todo de forma sencilla y automática.

\imgCentradaMed{fig.2.19}{img/hibernate.eps}{Logo Hibernate.}

\subsection{Valgrind}

\lettrine{A}{} la hora de hacer las pruebas es conveniente también asegurarnos de que nuestro código no tiene ninguna fuga de memoria que pudiera hacer que surgieran fallos o incluso que el sistema se colapsara, algunas pistas de que hay errores de memorias son la disminución del rendimiento, que el programa vaya lento o que haya objetos devolviéndonos datos erróneos. Para hacer una comprobación del estado de la memoria usada por nuestro programa usaremos \emph{Valgrind}, un conjunto de herramientas de software libre que nos ayudará en este proceso. 

\imgCentradaMed{fig.2.20}{img/valgrind.eps}{Logo Valgrind.}

La herramienta más usada es \emph{Memcheck}, que permite realizar un seguimiento del uso de la memoria y detectar múltiples errores como uso de memoria no inicializada, lectura o escritura de memoria que ha sido previamente liberada, lectura o escritura fuera de los límites del bloque de memoria dinámica, fugas de memoria, etcétera.

El uso de Valgrind sobre nuestro programa relentiza considerablemente el rendimiento de éste, se ejecuta mucho más lento, por eso es conveniente usarlo solo en momentos críticos, durante una búsqueda concreta de estos errores por ejemplo.

\newpage
Otras herramientas incluidas por Valgrind son Massif que mide el rendimiento de la porción de memoria total, Helgrind que detecta condiciones de carrera cuando varios procesos intentan acceder a la vez al mismo recurso o Cachegrind que mide el rendimiento de la caché durante la ejecución.

\imgCentrada{fig.2.21}{img/valgrindreport.eps}{Resltado Valgrind.}

\newpage
\subsection{Mavlink}

\lettrine{P}{ara} realizar las comunicaciones entre los distintos módulos que compondrán el simulador usaremos el protocolo de comunicaciones Mavlink que es el que se usará realmente en un vuelo con el UAV para el que realizaremos el entorno de simulación, es un protocolo de comunicaciones simple para aeronaves no tripuladas de menos de 25 kilogramos, se sopesó utilizar el protocolo definido por STANAG, el acuerdo de normalización de la OTAN, pero éste protocolo es más amplio y detallado y hubiéramos gastado demasiado tiempo en la implementación del protocolo que diseñando la funcionalidad del simulador que era lo que nos interesaba, además los componentes que vamos a usar, tanto el UAV como la GCS ya tienen implementados el protocolo Mavlink, por tanto nos aprovecharemos de esto para realizar la primera aproximación.

\imgCentrada{fig.2.22}{img/mavlink.eps}{Logo Mavlink.}

El protocolo Mavlink define una serie de interfaces a usar en las comunicaciones entre la estación de control de tierra y la aeronave y unos protocolos de utilidad durante el revuelo y la misión del avión como pueden ser carga de misión, ordenes, mensajes de error, monitorización de sensores, etcétera.

Cada mensaje del protocolo va a su vez encapsulado dentro de un paquete que guarda datos del envío como el número de secuencia de ese paquete, el sistema y el componente al que va destinado, un flag de control de envío, un flag de inicio de transmisión...

Es un protocolo muy extendido y tiene soporte para muchas plataformas, tanto software como hardware, se puede usar con los autopilotos Parrot AR.Drone, ArduPilot, PX4FMU, pxIMU, SmartAP, MatrixPilot, Armazilla 10dM3UOP88 y software como AndroidPilot, APM Planner 2.0, DroidPlanner, MAVProxy, MissionPlanner, QGroundControl(implementado por la compañía creadora de Mavlink). Éstos son los oficiales, mucha gente lo ha usado como nosotros para sus propios autopilotos a parte de los aquí redactados y tiene una gran comunidad detrás.

En nuestro sistema usaremos a parte de los mensajes de comando, monitorización y errores la secuencia definida por Mavlink para la escritura de la misión en el avión cuyo funcionamiento describiré a continuación para ilustrar el uso de los mensajes de éste protocolo.

\subsubsection{Escritura de misión con el protocolo Mavlink}

Desde la GCS se envía un primer mensaje hacia el UAV MISSION-COUNT, mensaje que pide iniciar una escritura de
misión y que lleva un campo con el número de waypoints que va a tener esa misión, luego el UAV, cuando recibe éste mensaje, responde con un MISSION-REQUEST con el número de waypoint que quiere pedir, en el primer caso será el waypoint con número de secuencia 0, al llegar ese mensaje a la GCS ésta sabrá que puede enviar el primer waypoint e inicia un contador de tiempo, si en un tiempo determinado no ha recibido el siguiente MISSION-REQUEST desde el UAV significa que ha habida algún problema en el envío por lo que tendremos que enviarlo otra vez, cuando ha llegado el mensaje al UAV éste vuelve a enviar un nuevo MISSION-REQUEST pidiendo el siguiente waypoint, cuando todos los waypoints han sido enviados el UAV envía un mensaje MISSION-ACK que informa a la GCS que ha llegadoo el último waypoint correctamente y la misión ha sido escrita entera en la aeronave. Éste protocolo se ilustra en la siguiente figura.

\imgCentrada{fig.2.23}{img/mavlinkwaypointwrite.eps}{Protocolo de escritura de misión en Mavlink.}

\newpage
\subsection{GCS}

\lettrine{U}{na} GCS o estación de control de tierra por sus siglas en ingles (Ground Control Station) es un centro de control que facilita a un ser humano el control de vehículos aéreos no tripulados en el aire o en el espacio. La estación de control de tierra te permite una comunicación directa con el UAV a la hora de mandarle comandos o programar una misión, cuando se realiza una misión hay que hacer una sesión de pre-vuelo donde se comprueba que todos los componentes del avión funcionan correctamente, luego se envía una orden de despegue y una vez volando se comanda una misión al UAV, una serie de waypoints y acciones que tendrá que realizar, en cualquier momento se puede enviar una orden de vuelta a casa, una orden de que permanezca en el sitio volando en círculos y otras muchas. Todo esto se controla desde la estación de control, que en todo momento monitoriza la posición del UAV, la información de telemetría que nos envía, el estado de la batería o la gasolina, los motores, la attitud, etcétera.

\imgCentrada{fig.2.24}{img/qgroundcontrol.eps}{QGroundControl, gcs de Mavlink.}

En nuestro caso usaremos la GCS creada por los departamentos de Aviónica y Sistemas No Tripulados y Simulación y Software de FADA-Catec, La GCS de Catec nos permite realizar las operaciones necesarias para probar nuestro sistema, usa el protocolo de comunicaciones Mavlink mediante UDP, nosotros le realizaremos una modificación para que pueda comunicarse con el resto de módulos mediante ANIMO DDS. Con ésta GCS podemos monitorizar los datos del UAV, comandarle una misión, comandarle que haga \emph{loiter} (Que gire en torno a un waypoint) o que entre en \emph{failsafe} y vaya a una zona segura. También incorpora una pantalla de monitorización de alarmas que nos indica en todo momento el estado de la aeronave.

La GCS de Catec está basada en plugins, por lo que su funcionalidad es ampliable, disponemos de plugins de monitorización 3D de la aeronave, plugins de control de waypoints, plugins de monitorizaciónes de telemetría, de control de carga de pago, etcétera.

Nosotros hemos creado un plugin de comunicación para ANIMO DDS el cual transforma los mensajes que maneja la GCS a mensajes que puedan viajar mediante ANIMO DDS para que puedan comunicarse con nuestro simulador.

\imgCentrada{fig.2.25}{img/gcscatec.eps}{GCA de Catec.}

\newpage

\subsection{Locomove}

\lettrine{F}{ADA}-Catec dispone de varias aeronaves de desarrollo propio, para nuestro simulador usaremos el avión eléctrico no tripulado Locomove. Es un RPAS ligero con un motor eléctrico que destaca por sus prestaciones de carga de pago, autonomía y rango de vuelo para el desarrollo de aplicaciones en diferentes ámbitos. Es un avión de ala fija con una envergadura de algo más de dos metros, es de despegue manual, por lo que no necesita pista de despegue y una autonomía de unos 45 a 60 minutos, puede llevar una carga de pago de un kilo y alcanza velocidades de entre 60 y 100 kilómetros por hora.

Al estar el autopiloto de este dispositivo preparado para trabajar con el resto de nuestros componentes y estar realizado íntegramente en el centro supone un sujeto de pruebas perfecto ya que tenemos total control sobre sus componentes y a su vez el proyecto servirá para depurar fallos en el mismo avión y poder probar las nuevas funcionalidades que se le añadan antes de realizar un vuelo real.

\imgCentrada{fig.2.26}{img/locomove.eps}{UAV de Catec, Locomove.}

\newpage

\subsection{Autopiloto}

\lettrine{E}{l} autopiloto embarcado dentro del UAV Locomove ha sido diseñado y fabricado por el departamento de Aviónica y Sistemas No Tripulados de FADA-Catec, es un disipositivo montado sobre una placa \emph{BeagleBone}, una placa de bajo consumo y hardware libre que contiene en un único panel un ordenador completo, está pensada para utilizar software libre y se usa debido a su pequeño tamaño y peso y gran flexibilidad a la hora de desarrollar sobre ella. Las barrica la empresa americana Texas Instruments junto con Digi-key y Newmark element14.

La BeagleBone dispone de un procesador Cortex-A8, una memoria DDR2 de 256 MB de capacidad, una ranura para memorias microSD, una entrada Fast Ethernet, y una entrada de alimentación de 300-500 mA y 5 V mini USB.

El sistema operativo utilizado en el autopiloto es QNX, un sistema operativo en tiempo real de tipo Unix desarrollado para su uso en sistemas embebidos por QNX Software Systems, empresa adquirida por BlackBerry. Está basado en una estructura micronúcleo que proporciona características de estabilidad avanzadas frente a fallos de dispositivos, aplicaciones, etcétera. Los sistemas operativos de tiempo real son interesantes para situaciones donde sea absolutamente necesaria una toma continua de, por ejemplo, muestra de datos. Basándose en este interés, existen diversos proyectos para crear nuevas versiones en tiempo real de otros sistemas. Está orientado a su utilización en microcontroladores y sistemas críticos como podría ser nuestro ordenador embarcado.

El autopiloto se compone de varios módulos funcionales, cada uno con una misión bien definida. Por una parte tenemos un módulo de tratamiento de mensajes que es el encargado de hacer llegar a cada componente su respectivo mensaje, otro módulo se encarga de manejar la máquina de estados de la aeronave, también hay un módulo de control y guiado de la misión y un estimador que ayuda al pilotaje del avión. 

A parte de los módulos incluidos y necesarios para el vuelo real del UAV, en nuestro autopiloto se incluirá un módulo dedicado a emular los sensores del avión, ya que nuestro autopiloto no estará volando realmente no podrá leer datos de posición GPS ni de velocidad de viento etc, por tanto estos datos se los proporcionaremos nosotros simulando el entorno real de vuelo. Este modulo llamado \emph{modelo} del avión nos devolverá respuestas frente a órdenes enviadas por el autopiloto de la misma forma que lo harían los servos y sensores del UAV Locomove. Más adelante se implantará la posibilidad de cambiar éste modelo para poder emular diferentes tipos de aviones en nuestro entorno.

\newpage
Quitando el modelo incorporado al autopiloto el resto del sistema es exactamente el mismo sistema que va embarcado dentro del UAV, por tanto tenemos la seguridad que el tratamiento y la respuesta será exactamente igual que en unas condiciones de vuelo real.

\imgCentrada{fig.2.27}{img/autopilotocatec.eps}{Autopiloto integrado en el Locomove.}


%%%%%%%%%%%%%%%%%%%%%PARTE 2 SISTEMA A DESARROLLAR%%%%%%%%%%%%%%%%%%%%


\part{Sistema a desarrollar}
\chapter{Planificación inicial}
\section{Lanzamiento del proyecto}

\lettrine{A}{} principios del mes de Octubre de 2013 se reúne el equipo de desarrollo del proyecto SIMFORPAS formado por Irene Alejo, Jaime Rey, Manuel Mateos y Yamnia Rodríguez junto con Pablo Morillas desarrollado de la GCS en carácter de experto sobre comunicaciones entre GCS y UAV y manejo de la GCS. Ésta reunión constituye la primera etapa del desarrollo incremental guiado por Scrum, en ella se definirán los roles existentes y se pondrán en común las historias de usuario necesarias para la consecución de los objetivos del proyecto.

\subsection{Definición de roles}

\lettrine{S}{e} ponen en común los posibles roles que participarán en el desarrollo entre los que salen el cliente, que comprará la aplicación, los usuarios que serán el instructor y el alumno, el equipo de desarrollo y el instalador del sistema. Estos actores tendrán sus requerimientos sobre el sistema y sus exigencias sobre la funcionalidad que tiene que darse en él para su beneficio. Por tanto haremos una descripción de la función de cada uno y después los usaremos para definir las historias de usuarios.

Al ser un proyecto de investigación sobre ésta tecnología no disponemos de un cliente, si en un futuro se pretende vender éste producto nos pondremos nosotros mismos en el papel del cliente imaginando cómo debe ser el producto final.

\begin{itemize}
\item\textbf{Instructor:} Será el encargado de manejar el puesto de instructor mediante el cual podrá recibir datos del puesto de un alumno y en base a la información intercambiada decidir si éste es apto o no para recibir un título de operador de GCS.

El instructor necesitará herramientas que le permitan evaluar los conocimientos del alumno. Deberá visualizar cuando sea preciso el puesto del alumno para monitorizar sus acciones, ser capaz de introducir errores en el modelo para comprobar la reacción del alumno y guardar un log con la evolución de la misión.

\item\textbf{Alumno:} Este actor será evaluado por un instructor haciendo uso del sistema. Requerirá disponer de una GCS que simule un entorno real de pilotaje de UAV, un instructor que le cargue una misión y supervise durante el desarrollo de la misma. El sistema deberá tener unas condiciones lo más parecidas a un caso real para comprobar que los conocimientos adquiridos por el alumno son correctos y pueden usarse en un entorno real.

\item\textbf{Desarrollador:} Es el encargado del diseño, escritura y posterior montaje del sistema. Necesitará para ello información verídica sobre los requisitos que se necesitan, un entorno de desarrollo adecuado y las herramientas necesarias.

\item\textbf{Instalador del sistema:} Es el actor encargado de preparar los equipos para que trabajen con el software desarrollado durante el proyecto. Necesitará un equipo adecuado para instalar el puesto del alumno y otro para el del instructor, que el software disponga de un instalador con todas las herramientas necesarias para el correcto funcionamiento del sistema.

\item\textbf{Cliente:} Será el interesado en adquirir el software para instruir a futuros operadores de GCS. Necesitará un entorno de aprendizaje que simule fielmente las condiciones de pilotaje de UAV y permita a un instructor ser capaz de evaluar al alumno.

\end{itemize}

\subsection{Historias de usuario}

\lettrine{A}{} partir de los actores del proyecto se definirán las historias de usuario. Una historia de usuario es una representación de un requisito de software escrito en una o dos frases utilizando el lenguaje común del usuario. Éstas historias de usuario son utilizadas en la metodología Scrum para la especificación de requisitos. Cada historia de usuario debe ser limitada, esta debería poderse escribir sobre una nota adhesiva pequeña. Son una forma rápida de administrar los requisitos de los usuarios sin tener que elaborar gran cantidad de documentos formales y sin requerir de mucho tiempo para administrarlos. Las historias de usuario permiten responder rápidamente a los requisitos cambiantes. Vamos a enumerar características que deben cumplir las historias de usuario.

Deben ser:

\begin{itemize}
\item\textbf{Independientes unas de otras:} De ser necesario, combinar las historias dependientes o buscar otra forma de dividir las historias de manera que resulten independientes.

\item\textbf{Negociables:} La historia en si misma no es lo suficientemente explícita como para considerarse un contrato, la discusión con los usuarios debe permitir esclarecer su alcance y éste debe dejarse explícito bajo la forma de pruebas de validación.

\item\textbf{Valoradas por los clientes o usuarios:} Los intereses de los clientes y de los usuarios no siempre coinciden, pero en todo caso, cada historia debe ser importante para alguno de ellos más que para el desarrollador.

\item\textbf{Estimables:} Un resultado de la discusión de una historia de usuario es la estimación del tiempo que tomará completarla. Esto permite estimar el tiempo total del proyecto.

\item\textbf{Pequeñas:} Las historias muy largas son difíciles de estimar e imponen restricciones sobre la planificación de un desarrollo iterativo. Generalmente se recomienda la consolidación de historias muy cortas en una sola historia.

\item\textbf{Verificables:} Las historias de usuario cubren requerimientos funcionales, por lo que generalmente son verificables. Cuando sea posible, la verificación debe automatizarse, de manera que pueda ser verificada en cada entrega del proyecto.

\end{itemize}

Después de definir todas las historias de usuario hay que valorar la dificultad de cada una de las historias de usuario para hacer una estimación del tiempo necesario para llevarlas a cabo.  El siguiente paso consiste en darles a cada una una prioridad basada en la necesidad que tenemos de que se realicen primero o de la importancia que tengan en el sistema. Ahora enumeraremos las historias de usuario propuestas durante la reunión de lanzamiento del proyecto y la importancia que se le dio a cada uno, a mayor número junto a la historia de usuario mayor importancia tendrá, también añadiremos el grado de dificultad de cada historia, para dar una imagen global de como usar los puntos, un grupo de trabajo de cuatro personas tiene una velocidad aproximada de 20 puntos por semana.

\begin{itemize}

\item Como cliente quiero que el desarrollo del simulador se lleve usando las herramientas y metodologías necesarias para augurar el éxito en el desarrollo del proyecto.
\\
\textbf{Dificultad: }2
\\
\textbf{Prioridad: }9990

\item Como desarrollador quiero tener bien definida la arquitectura básica a alto nivel y las herramientas principales que se van a utilizar para no perder la vista del objetivo principal del proyecto.
\\
\textbf{Dificultad: }2
\\
\textbf{Prioridad: }9980
\item Como instructor quiero que las comunicaciones entre los sistemas se realice en tiempo real como uno de los puntos para garantizar el entrenamiento veraz.
\\
\textbf{Dificultad: }3
\\
\textbf{Prioridad: }9890
\item Como desarrollador quiero poder insertar un modelo simple de UAV en el simulador para ayudar a definir el método de carga de modelos físicos.
\\
\textbf{Dificultad: }3
\\
\textbf{Prioridad: }9880
\item Como desarrollador quiero un módulo central capaz de cambiar y monitorizar el estado del modelo.
\\
\textbf{Dificultad: }5
\\
\textbf{Prioridad: }9790
\item Como desarrollador quiero un módulo que emule las GCS en el envío y recepción de datos para no depender de las GCS a la hora de desarrollar el resto de módulos y tener así el bucle completo cerrado GCS-SIMCore-SIMModel.
\\
\textbf{Dificultad: }3
\\
\textbf{Prioridad: }9780
\item Como cliente quiero que el modelo contemple la carga de los datos de misión utilizados en el protocolo Mavlink.
\\
\textbf{Dificultad: }5
\\
\textbf{Prioridad: }9785
\item Como desarrollador quiero que el módulo central esté sincronizado con el modelo para asegurar que los datos son coherentes.
\\
\textbf{Dificultad: }8
\\
\textbf{Prioridad: }9775
\item Como instructor quiero que las GCS visualicen la telemetría del UAV simulado para tener control de la misión.
\\
\textbf{Dificultad: }5
\\
\textbf{Prioridad: }9770
\item Como instructor quiero que el modelo del UAV sea lo más real posible para garantizar los conocimiento del alumno.
\\
\textbf{Dificultad: }8
\\
\textbf{Prioridad: }9760
\item Como cliente quiero que el desarrollo del puesto de instructor se lleve usando las herramientas y metodologías necesarias para augurar el éxito en el desarrollo del proyecto.
\\
\textbf{Dificultad: }2
\\
\textbf{Prioridad: }9755
\item Como instructor quiero usar el autopiloto real para realizar el entrenamiento y examen.
\\
\textbf{Dificultad: }8
\\
\textbf{Prioridad: }9754
\item Como instructor quiero que las GCS establezcan un plan de vuelo para la misión simulada.
\\
\textbf{Dificultad: }8
\\
\textbf{Prioridad: }9750
\item Como instructor quiero poder iniciar la simulación para tener control de la misión.
\\
\textbf{Dificultad: }8
\\
\textbf{Prioridad: }9680
\item Como instructor quiero poder parar la simulación para tener control de la misión.
\\
\textbf{Dificultad: }5
\\
\textbf{Prioridad: }9670
\item Como instructor quiero poder pausar la simulación para tener control de la misión.
\\
\textbf{Dificultad: }5
\\
\textbf{Prioridad: }9660
\item Como instructor quiero introducir fallos de pérdida total de comunicación para poner a prueba al alumno.
\\
\textbf{Dificultad: }8
\\
\textbf{Prioridad: }9650
\item Como instructor quiero visualizar las GCS para tener controlado al alumno.
\\
\textbf{Dificultad: }5
\\
\textbf{Prioridad: }9590
\item Como instructor quiero crear misiones para tener una batería de exámenes.
\\
\textbf{Dificultad: }2
\\
\textbf{Prioridad: }9580
\item Como instructor quiero grabar misiones que he generado en las GCS para poner a prueba al alumno en diferentes contextos.
\\
\textbf{Dificultad: }5
\\
\textbf{Prioridad: }9570
\item Como instructor quiero cargar misiones que he generado en las GCS para poner a prueba al alumno en diferentes contextos.
\\
\textbf{Dificultad: }2
\\
\textbf{Prioridad: }9560
\item Como instalador quiero que el sistema completo sea sencillo de administrar en instalar.
\\
\textbf{Dificultad: }1
\\
\textbf{Prioridad: }9490
\item Como Instructor, quiero tener acceso a información que me indique, paso a paso, el funcionamiento del puesto de instructor.
\\
\textbf{Dificultad: }1
\\
\textbf{Prioridad: }9480
\item Como instructor quiero que el modelo del UAV sea lo más real posible para garantizar los conocimiento del alumno.
\\
\textbf{Dificultad: }20
\\
\textbf{Prioridad: }8990
\item Como instructor quiero cambiar las condiciones del entorno (lluvia, viento?) para poner a prueba al alumno.
\\
\textbf{Dificultad: }20
\\
\textbf{Prioridad: }8980
\item Como instructor quiero elegir un UAV para la misión con el objetivo de evaluar al alumno en un UAV concreto.
\\
\textbf{Dificultad: }8
\\
\textbf{Prioridad: }8970
\item Como Instructor quiero almacenar/ consultar resultados de las pruebas para posterior evaluación o consulta a histórico del alumno.
\\
\textbf{Dificultad: }5
\\
\textbf{Prioridad: }8960
\item Como instructor quiero tomar y guardar anotaciones sobre el examen de un alumno para posterior evaluación.
\\
\textbf{Dificultad: }3
\\
\textbf{Prioridad: }8950

\end{itemize}

Una vez tenemos todos estos datos podemos realizar el documento de backlog, un documento de alto nivel para todo el proyecto. Éste documento va a ir incluyendo gráficas que representan la evolución del proyecto en cada sprint.

\imgCentradaGrande{fig.3.1}{img/documentobacklog.eps}{Ejemplo del documento de backlog.}

Se concretan las acciones para el primer sprint, que consistirán en realizar documentación sobre la estructura que tendrá el proyecto, estudio de interfaces y set up de los entornos de trabajo.


%%%%%%%%%%%%%%%%%%%%%SPRINTS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\chapter{Iteraciones: Sprints de desarrollo}

\section{Sprint 1: Set Up del proyecto}

\lettrine{U}{na} vez estudiados los requisitos del sistema a partir de las historias de usuario pasaremos a desarrollar la estructura global del sistema y a documentarlo todo. 

\subsection{Módulos del sistema}

Se necesitará una serie de módulos que tengan una función definida cada uno de ellos con el fin de hacer el sistema lo más escalable posible de manera que si en algún momento hay que realizar un cambio grande no afecte al resto de componentes, cada módulo será un proyecto independiente para descentralizar el desarrollo, así se determina la necesidad de disponer de los siguientes elementos:

\begin{itemize}
\item\textbf{Control:} Recibe un comando de control (Waypoint, velocidad, acción de algún sensor, etc) y calcula qué cambios hay que realizar en el modelo para alcanzarlo. El autopiloto puede ser parte del módulo de control.

\item\textbf{Modelo:} Simula las condiciones del entorno y comportamiento del UAV. Utilizará modelos lo más reales posibles. Mantendrá en todo momento un estado coherente del sistema, es decir, un cambio en alguno de sus parámetros afectará al resto según las reglas de la física y de comportamiento que se hayan implementado.

\item\textbf{Simulador:} Coordina el funcionamiento del resto de módulos y monitoriza el estado del sistema en cada momento. Gestiona el flujo de información entre los distintos módulos durante la ejecución del programa.

\item\textbf{GCS:} Estación de comando y de control del UAV. Es la interfaz entre el sistema y el operador, muestra en todo momento el estado del modelo y la misión. Esta será la plataforma sobre la que el operador será entrenado y evaluado. El Instructor debe tener visibilidad sobre lo que el operador está haciendo en cada momento durante el desarrollo de la misión.

\item\textbf{Puesto de instructor:} Sirve de interfaz entre el instructor y el sistema, desde ella se podrá cargar un modelo, una misión y controlar las acciones del alumno durante la misma. También permitirá introducir errores o cambios en el sistema durante una misión con el fin de evaluar la reacción del alumno.

\end{itemize}

Es necesario un elemento central que controle el flujo en información entre el resto de módulos y los sincronice para que no se produzcan situaciones de pérdidas de datos o de desfases de tiempo entre los distintos módulos que puedan provocar errores. Otro de los elementos necesarios será el llamado modelo del avión, éste modelo en una primera instancia deberá de disponer de un sistema de guiado y de tratamiento de acciones como la de la carga y gestión de la misión de forma que nos pueda devolver datos de telemetría actualizados según las condiciones globales del sistema. También se dispondrá de un puesto de instructor que permitirá a un examinador monitorizar la misión del alumno y de modificar las condiciones para comprobar su reacción. Por último haremos uso de la GCS ya implementada por Catec para que el alumno maneje el simulador.

\subsection{Estructura del sistema}

Al final la arquitectura queda dispuesta de la siguiente manera, comunicándose todos los módulos mediante ANIMO DDS:

\imgCentradaGrande{fig.4.1}{img/arquitectura.eps}{Arquitectura del sistema, con las relaciones físicas entre subsistemas.}

Como podemos observar en el diagrama de arquitectura, el proyecto se dividirá en módulos que se encargarán de una función específica. Para realizar la interconexión entre los diferentes módulos usaremos el Framework de comunicaciones ANIMO para garantizar que las comunicaciones se establecen en tiempo real.

El módulo del modelo y el control serán desarrollados con Matlab-Simulink. Para el simulador se usarán tecnologías web y servicios web para comunicarse con él (haciendo uso de ANIMO).

En el caso de las bases de datos necesarias para guardar información sobre modelos de UAV, de entorno y misiones se hará uso de bases de datos no relacionales debido a que son más fáciles de diseñar, administrar y proveen de una mejora sustancial en la velocidad del sistema.

La GCS permitirá al usuario crear, modificar e incluso cargar misiones y modelos desde un archivo externo al sistema, el código que gestiona el funcionamiento de la GCS estará desarrollado en C++ y la parte encargada de la interfaz de usuario se realizará usando las bibliotecas QT.

\subsection{Diagramas de secuencia}

Una vez estudiados los elementos necesarios haremos una lista de las interfaces u objetos que necesitaremos manejar durante la ejecución de nuestro programa. Para ello tuvimos una reunión con el equipo que trabaja en el desarrollo de la estación de control para saber qué datos manejan ellos, conocer las entradas y salidas de su aplicación, los pasos de ejecución etcétera. Como nosotros debemos simular el comportamiento de la aeronave vamos a definir una serie de diagramas de secuencias donde se definan las distintas acciones que implementaremos en nuestra aplicación.

\begin{itemize}
\item\textbf{Funcionamiento básico durante la ejecución de una misión}

\imgCentradaGrande{fig.4.2}{img/funcionamientobasicomision.eps}{Diagrama de secuencia de la ejecución de una misión.}

En el primer paso la GCS envía una señal de inicio de ejecución de una misión al simulador que reenvía al control. El control envía el estado inicial al modelo que responde con el estado actualizado que más tarde se envía al simulador para mostrarlo en la GCS.

A continuación se inicia el bucle principal de la misión, el cual acabará cuando se hayan alcanzado todos los Waypoints. El control envía un Waypoint al modelo, que responde con su estado el cual se envía al simulador para mostrarlo en la GCS. Una vez alcanzado este Waypoint el control procedera? a enviar el siguiente. Cuando se hayan alcanzado todos los Waypoints ha acabado la misión y el simulador envía un mensaje a la GCS.

\item\textbf{Carga de la misión en el simulador y en control}

\imgCentradaGrande{fig.4.3}{img/cargamision.eps}{Diagrama de secuencia de la carga de una misión en el simulador y el control.}

El método de carga de la misión está basado en el protocolo MAVLINK. La GCS envía el número de Waypoints de la misión al simulador, que hace de puente de comunicación entre el control y la GCS, el control pide uno a uno los waypoint y la GCS se los va mandando. Cuando recibe el último waypoint el control envía un mensaje de fin de carga de la misión. En el protocolo de escritura de misiones en el UAV de MAVLINK cuando se envía un mensaje que espera respuesta se inicia un timer si se consume ese tiempo sin respuesta se realiza otra vez la petición, esta acción la realizará el simulador.

\item\textbf{Inicio, parada y pausa de la simulación}

\imgCentradaGrande{fig.4.4}{img/iniciopausaparada.eps}{Diagrama de secuencia con los comandos desde el puesto de instructor para iniciar, parar o pausar una ejecución.}

El primer comando es enviado por el puesto de instructor al simulador para que éste establezca las comunicaciones con cada uno de los módulos para iniciar la ejecución.
El segundo comando muestra el flujo de información al cargar el modelo desde el puesto de instructor. El instructor selecciona el modelo a cargar (tanto del entorno como del UAV), el simulador recibe ese modelo y lo carga en el módulo ?Modelo? y se envía un mensaje al simulador mostrando si ha ocurrido algún error durante la carga.
El tercer comando muestra al alumno cargando (o creando) una misión, la cual enviará al simulador y éste le devolverá un mensaje con el resultado de la carga.
El cuarto es la operación anterior pero realizada desde el puesto de instructor, carga la misión en el simulador, la inicializa en la GCS y se envía el correspondiente mensaje de errores.
Los dos últimos comandos muestran el funcionamiento de las órdenes de parada y reanudación, las cuales se realizarán sobre el módulo de control.

\item\textbf{Introducción de fallos en el modelo}

\imgCentradaGrande{fig.4.5}{img/introduccionfallos.eps}{Diagrama de secuencia para la introducción de fallos.}

El diagrama muestra el intercambio de datos cuando el instructor desea introducir errores en el sistema con el fin de comprobar la reacción del alumno. Se selecciona el error a introducir en el puesto de instructor y se notifica al simulador, se procesa el error y se actualiza el modelo, el modelo realiza los cambios necesarios y para finalizar el simulador envía el nuevo estado del modelo a la GCS.

En otra posible solución el control es el que detecta el fallo una vez se ha introducido en el modelo y genera el mensaje de error que envía al simulador para que se lo comunique a la GCS.

\item\textbf{Cambios en la misión}

\imgCentradaGrande{fig.4.6}{img/cambiosmision.eps}{Diagrama de secuencia para hacer cambios en la misión.}

Estas transacciones explican el intercambio de información en el caso en que se introdujeran cambios en la misión durante el vuelo (introducción de un nuevo Waypoint o cambios en el modelo de UAV como velocidad etc). La GCS introduce o modifica un Waypoint o modifica algún parámetro en el UAV y se lo comunica al simulador que es donde está almacenada la misión, el simulador le envía el nuevo Waypoint o parámetro al control cuando se lo pida.

\end{itemize}

\subsection{Diagrama de comunicaciones}

Una vez tenemos las acciones que va seguir nuestro programa podemos hacer un diagrama de cómo se van a comunicar los distintos módulos y de esta manera simplificar la información que obtuvimos anteriormente.

\imgCentradaGrande{fig.4.7}{img/relacionescomunicacion.eps}{Diagrama de las relaciones a la hora de comunicarse de los distintos módulos.}

De esta forma se puede observar de un vistazo que el simulador será el centro de las comunicaciones del sistema, el control se comunicará con el simulador para recibir los comandos cuya interpretación pasará al modelo y devolverá al simulador el nuevo estado de éste. El puesto de instructor enviará las acciones al simulador que será el encargado de redirigirlas hacia el puesto del alumno, el control o de hacer la comunicación con la base de datos. El puesto del alumno se conectará al simulador y desde ahí manejará el control y el modelo. El puesto de instructor podrá comunicarse con el puesto del alumno para monitorizar las acciones de éste y poder evaluarle luego.

\newpage
\subsection{Entradas y salidas de los módulos}

Una vez sabemos qué datos se van a enviar entre los diferentes módulos podemos agrupar cada transacción según sean entradas o salidas de cada uno de los módulos de la siguiente manera:


\begin{enumerate}
\item Puesto de instructor
\\
\textbf{Salidas}

\begin{itemize}

\item Orden de inicio del sistema (tipo Command) $\rightarrow$ Simulador
\item Identificador del modelo (tipo Command) $\rightarrow$ Simulador
\item Misión (tipo Mission) $\rightarrow$ Simulador
\item Orden de parada (tipo Command) $\rightarrow$ Simulador
\item Orden de reanudación (tipo Command) $\rightarrow$ Simulador
\item Fallo en el sistema (tipo Error) $\rightarrow$ Simulador

\end{itemize}

\item Simulador
\\
\textbf{Entradas}

\begin{itemize}

\item Orden de inicio (tipo Command) $\leftarrow$ Puesto del instructor
\item Identificador del modelo (tipo Command) $\leftarrow$ Simulador
\item Confirmación de carga (tipo Error) $\leftarrow$ Modelo
\item Misión (creadas en la GCS) (tipo Mission) $\leftarrow$ GCS
\item Identificador de la misión (tipo Mission) $\leftarrow$ Puesto del instructor
\item Confirmación de recepción de misión (cuando el instructor carga una misión en el simulador la GCS debe darse cuenta) (tipo Error) $\leftarrow$ GCS
\item Orden de parada (tipo Command) $\leftarrow$ Puesto del instructor
\item Orden de reanudación (tipo Command) $\leftarrow$ Puesto del instructor
\item Orden de inicio de misión (tipo Command) $\leftarrow$ GCS
\item Nuevo estado del modelo (Al inicio, tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Modelo
\item Nuevo estado del modelo (En el bucle, tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Modelo
\item Fallo en el sistema (tipo Error) $\leftarrow$ Puesto de instructor
\item Nuevo estado del modelo (después del error, tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Modelo
\item Correcciones del alumno (después del error, tipo Command) $\leftarrow$ GCS


\end{itemize}

\textbf{Salidas}

\begin{itemize}
\item Carga modelo (tipos PosWgs , Rotation y VelEarth) $\rightarrow$ Modelo
\item Dato de confirmación (tipo Error) $\rightarrow$ GCS
\item Misión (tipo Mission) $\rightarrow$ GCS
\item Orden de parada (tipo Command) $\rightarrow$ Control
\item Orden de reanudación (tipo Command) $\rightarrow$ Control
\item Estado inicial del UAV (tipos PosWgs, Rotation y VelEarth) $\rightarrow$ Modelo
\item Waypoint (tipo FlightPlan) $\rightarrow$ Control
\item Introducción de error (tipo Command) $\rightarrow$ Modelo
\item Aviso de error (tipo ?Error) $\rightarrow$ GCS

\end{itemize}

\item GCS
\\
\textbf{Entradas}

\begin{itemize}

\item Orden de inicio (tipo Command) $\leftarrow$ Simulador
\item Confirmación de carga de la misión (tipo Error) $\leftarrow$ Simulador
\item Misión cargada por el instructor en el simulador (tipo Mission) $\leftarrow$ Simulador
\item Estado del modelo (tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Simulador
\item Aviso finalización (tipo Error) $\leftarrow$ Simulador
\item Aviso de error (tipo Error) $\leftarrow$ Simulador

\end{itemize}

\textbf{Salidas}

\begin{itemize}

\item Misión (tipo Mission) $\rightarrow$ Simulador
\item Confirmación de recepción de misión (tipo Error) $\rightarrow$ Simulador
\item Orden de inicio de misión (tipo Command) $\rightarrow$ Simulador
\item Reacción ante un problema (tipo Command) $\rightarrow$ Simulador

\end{itemize}

\item Modelo
\\
\textbf{Entradas}

\begin{itemize}

\item Orden de inicio (tipo Command) $\leftarrow$ Simulador
\item Tipo de dato modelo (tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Simulador
\item Estado inicial del UAV (tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Simulador
\item Consulta estado del modelo (tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Control
\item Actualiza el modelo (tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Control
\item Actualiza modelo con el error (tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Modelo

\end{itemize}

\textbf{Salidas}

\begin{itemize}

\item Confirmación de carga (tipo Error) $\rightarrow$ Simulador
\item Comunica el estado inicial (tipos PosWgs , Rotation y VelEarth) $\rightarrow$ Simulador
\item Publica estado actual (tipos PosWgs , Rotation y VelEarth) $\rightarrow$ Control
\item Comunica nuevo estado del modelo (tipos PosWgs , Rotation y VelEarth) $\rightarrow$ Simulador
\item Actualiza el nuevo estado (después de error, tipos PosWgs , Rotation y VelEarth) $\rightarrow$ Simulador

\end{itemize}

\item Control
\\
\textbf{Entradas}

\begin{itemize}

\item Orden de inicio (tipo Command) $\leftarrow$ Simulador
\item Orden de parada (tipo Command) $\leftarrow$ Simulador
\item Orden de reanudación (tipo Command) $\leftarrow$ Simulador
\item Waypoint (tipo FlightPlan) $\leftarrow$ Simulador
\item Estado actual del modelo (tipos PosWgs , Rotation y VelEarth) $\leftarrow$ Modelo

\end{itemize}

\textbf{Salidas}

\begin{itemize}

\item Consulta estado del modelo (tipo Command) $\rightarrow$ Modelo
\item Actualiza el modelo (tipos PosWgs , Rotation y VelEarth) $\rightarrow$ Modelo

\end{itemize}

\end{enumerate}

\subsection{Definición de interfaces}

A la hora de empezar a programar nuestra aplicación necesitamos conocer qué clases vamos a tener y qué información guardará cada una, ya que hemos realizado el ejercicio de anotar todas las comunicaciones de datos que se realizarán entre nuestros módulos y de las entradas y salidas de cada uno de ellos ya sabemos qué datos manejará cada uno, por tanto, definiremos cuáles son los datos que tenemos que modelar con clases.

\imgCentradaGrande{fig.4.8}{img/definicioninterfaces.eps}{Definición de interfaces.}

\newpage
\subsection{Diagrama de burndown}

Para el primer sprint se esperaba realizar el documento de análisis inicial con un valor de dificultad de dos puntos y la definición de interfaces con otros dos puntos. Al haber realizado las dos acciones finalizamos el sprint con un total de 4 puntos en la evolución de velocidad de la iteración que plasmaremos en el siguiente diagrama de velocidad.

\imgCentradaGrande{fig.4.9}{img/diagvelocidad1.eps}{Diagrama de velocidad para el primer sprint.}

\newpage
\subsection{Diagrama de evolución}

El diagrama de evolución nos muestra las historias de usuario que hemos realizado frente a las totales del proyecto, lo que nos da una idea aproximada de lo que nos queda para finalizar.

\imgCentradaGrande{fig.4.10}{img/diagevolucion1.eps}{Diagrama de evolución para el primer sprint.}


\newpage
\section{Sprint 2: Creación de la capa de comunicación}

\lettrine{E}{ste} sprint lo dividiremos en tres partes, en un principio explicaremos los pasos necesarios para poner a punto las herramientas que usaremos durante el desarrollo del proyecto, entornos de programación, librerías necesarias, etcétera. En la segunda parte explicaremos cómo se implementó la capa de comunicación de los distintos módulos para realizar el intercambio de datos entre ellos, parte muy importante en el proyecto, también explicaremos como se usa ANIMO DDS. Para terminar realizaremos una primera integración del simulador con un modelo simple que acepta una trayectoria tomando un camino rectilíneo de un punto a otro de la misión.

\subsection{Set up del entorno de desarrollo}

\lettrine{E}{l} primer paso a la hora de iniciar el desarrollo del proyecto debe ser el de disponer de un entorno de desarrollo con todas las herramientas necesarias a la hora de llevar a cabo la programación de nuestro sistema, para ello haremos un recuento de las tecnologías que vamos a usar e instalaremos las correspondientes herramientas que faciliten el uso de éstas tecnologías.

\subsubsection{Entorno de desarrollo C++}

Ya que la mayor parte del proyecto va a ser desarrollado en el lenguaje de programación C++ debemos disponer de un entorno de programación adecuado. Decidimos hacer uso de la herramienta de generación de proyectos en C++ Cmake, la cual nos resultará muy útil a la hora de crear varios proyectos que tengan las mismas características y usen las mismas tecnologías. Al decidir hacer uso de CMake nos decantamos por trabajar con el entorno de desarrollo integrado o \emph{IDE} (Integrated Development Enviroment) QtCreator ya que éste tenía una mejor integración con CMake sobre la otra opción que tuvimos que era usar el entorno Eclipse adaptado a C++ que, a parte de ser más lento al ejecutarse en la máquina virtual de Java, disponía de herramientas útiles a la hora de trabajar con CMake y con las librerías de C++ Qt de las que haremos uso más adelante.

Tanto la última versión de Qt como el entorno de desarrollo QtCreator lo podemos encontrar en la página del proyecto \emph{http://qt-project.org}.

Una vez disponemos de este entorno de desarrollo ya podemos crear nuestro primer proyecto con C++.

\subsubsection{Creación del repositorio y la estructura de carpetas}

Ahora que tenemos el proyecto creado nos creamos un repositorio, usamos bitbucket ya que es el más usado por el departamento de Simulación y Software de Catec. Mediante la herramienta TortoiseHG podremos manejar nuestro repositorio desde el escritorio. La metodología de trabajo será la siguiente: nos crearemos un \emph{fork} del repositorio principal, subiremos todas las modificaciones que realicemos a ese fork, y cada vez que tengamos una versión estable del sistema haremos una petición de unión con el repositorio principal o \emph{pull request}. Para la estructura de carpetas se definió que la ruta principal tendría dos carpetas, una destinada al código y otra a la documentación, dentro de la carpeta código la estructura sería crear una carpeta por cada módulo o proyecto que se necesite en el sistema.

\subsubsection{Instalación ANIMO DDS}

El primer paso que tomamos una vez pudimos empezar a generar nuestro código en C++ fue el de instalarnos las librerías de ANIMO proporcionadas por Catec e integrarlas en un proyecto de prueba que consistía en dos aplicaciones, una que permitía tomar datos de un joystick conectado por USB al ordenador, enviar éstos datos por ANIMO y recibirlos en otra aplicación que dibujaba un punto sobre una ventana representando el movimiento del joystick.

El primer paso es descargarse las librerías de RTI DDS, las podemos encontrar en la siguiente url \emph{http://www.rti.com/downloads/connext-files.html/}, una vez tenemos el archivo de instalación debemos darle permisos de ejecución y ejecutarlo, aceptar las condiciones de uso y seleccionar el directorio de instalación. Antes de ejecutarlo debemos revisar algunas dependencias que tienen estas librerías, debemos tener instaladas en nuestro sistema las librerías \emph{libtiff3} y \emph{libjpeg62}. Una vez termine la instalación de RTI DDS debemos de hacernos con un archivo de licencia, en nuestro caso fue provisto por Catec, y lo copiamos en la carpeta de instalación de RTI.

Lo siguiente es instalar el paquete debian creado por el equipo de desarrollo de ANIMO DDS de Catec, el cual se instalará con el correspondiente comando desde nuestra terminal de Ubuntu.

Una vez tenemos todas las librerías instaladas correctamente podemos hacer la implementación de nuestra primera prueba de comunicaciones mediante ANIMO DDS.

\textbf{Uso de las librerías de ANIMO DDS: }El uso es bastante sencillo, sólo basta con inicializar ANIMO obteniendo una instancia del framework a partir de un archivo de configuración en el que se indica el dominio o "canal" por el que se van a transmitir los datos, las calidades de servicios, la ruta del fichero donde se encuentran la definición de calidades, la ruta del log y el identificador del log. A partir de este objeto crearemos dos instancias de los llamados "Acces Points" que son los objetos que usaremos para publicar y subscribirnos. La dinámica de funcionamiento del patrón publicador subscriptor es muy sencilla, una aplicación publica un dato bajo un tópico y éste dato es recibido por todas las aplicaciones que estén subscritas a ese dato con ese tópico, así mediante el tópico podemos decidir qué datos vanos a recibir y cuales no, en nuestra aplicación asignaremos como tópico el identificador correspondiente al programa que ha enviado ese dato, por tanto el resto de módulos se subscribirán al identificador correspondiente a los módulos que envían información que él necesita. Entonces nos crearemos un objeto AccessPointForSending y otro objeto AccessPointForReceiving.

A la hora de enviar un dato lo único que necesitamos hacer es tomar la instancia de nuestro AccessPointForSending y llamar a su método sendInterfaceData(data) donde "data" es cualquier objeto que herede de la clase "I\_Data" de ANIMO DDS. La recepción del dato se hará mediante listeners, un listener es un objeto que tendrá un método process el cuál será llamado cuando haya llegado un dato que esté destinado a ese listener proporcionándole el dato. Para que ese listener reciba ese dato debemos registrarlo mediante el framework de ANIMO, más concretamente haciendo uso del AccessPointForReceiving el cual tiene dos métodos, uno llamado registerInterface(Type, listener) el cual recibe un enumerado con el tipo de dato que se va a recibir en ese listener y un listener que debe heredar del tipo de ANIMO I\_DataListener el cual posee un método process que es el que recibirá el dato.

Los tipos que pueden ser enviados mediante ANIMO debemos definirlos antes y, haciendo uso de las herramientas de generación de código de ANIMO DDS, recoger sus propiedades dentro de un archivo de configuración a partir del cual ANIMO automáticamente generará las clases necesarias para el envío de ese dato por DDS y hará las modificaciones pertinentes en el framework, incluido el añadir al enumerado de tipos que se pueden enviar por ANIMO el nuevo dato, enumerado que necesitaremos en el AccessPointForReceiving. Después de esto debemos generar los paquetes debían de nuevo mediante un script incluido en el proyecto ANIMO DDS y volver a instalarlos.

El siguiente paso es indicarle AccessPointForReceiving que va a recibir datos de un tópico para empezar a escuchar, por tanto se llamará a su método starDevice(Type, Topic) donde "Type" volverá a ser el enumerado con valor correspondiente al tipo de dato que vamos a recibir y "Topic" será el tópico bajo el que se va a enviar ese dato.

Así pues en el process del listener se define qué es lo que se va a hacer con ese dato. En nuestro caso la acción era modificar la posición de un punto en nuestra ventana según el valor de movimiento que nos hubiera mandado el joystick.

\subsection{Implementación de la capa de comunicación}

\lettrine{D}{espués} de la implementación del proyecto de prueba de comunicaciones con ANIMO se definió una estructura a seguir para el tratamiento de los datos. Según ésta estructura se definiría una clase contenedor para todos los elementos referentes a las comunicaciones y un tipo de listener especial para nuestro proyecto. A continuación explicaremos cómo están formados estos elementos.

\subsubsection{Contenedor}

El contenedor es la clase principal de nuestras comunicaciones mediante ANIMO, ésta estará encargada de establecer los elementos necesarios para iniciar las comunicaciones (creación de los Access Points, registros, etcétera...), crear los listeners que nos harán falta, almacenarlos y proveer al resto del proyecto de los métodos necesarios tanto para realizar un envío de un dato mediante DDS como para acceder a los datos que nos han llegado.

El constructor del container tiene como parámetros de entrada el archivo de configuración necesario para la inicialización de ANIMO y el dominio, ambos archivos los incluiremos en el archivo de configuración general de la aplicación que tendrá los parámetros característicos de cada módulo a parte de las configuraciones necesarias para las comunicaciones a través de ANIMO. También será encargado de inicializar el framework de ANIMO y de crear los Access Points, tanto el de subscriptor como el de publicador. Y por último inicializará los listeners necesarios para nuestro proyecto.

Uno de los métodos necesarios es el de subscribe(), el cual a partir de la lista de listeners que hemos creado y el tópico identificador para el módulo que estamos implementando subscribirá cada uno de los listeners para poder iniciar la recepción de datos.

También dispondrá de un método de envío que recibirá un dato de ANIMO a publicar y hará la llamada al AccessPointForSending que realizará el envío.

Por último, esta clase dispondrá de una serie de métodos observadores que devolverán cada uno de los datos a los que nos hemos suscrito.

\subsubsection{Listeners}

Debido a que queremos mantener un control sobre el flujo de datos entre los sistemas de que disponemos y sobre la ejecución de la simulación tenemos que marcar unas pautas que definan qué se va a hacer con los mensajes cuando nos llegan. Una opción consiste en hacer en el process del listener la llamada a la clase que vaya a usar ese dato o un controlador de datos que lo redirija al objeto en el que va a ser usado, esto podría darnos problemas y complicar mucho el flujo de ejecución elevando el riesgo de que se entre en condiciones de carrera, etcétera.

La segunda opción, por la que finalmente optamos fue la de almacenar dentro del listener los datos nuevos cuando llegan, por lo que los listeners tienen un atributo del tipo del dato que están esperando recibir, el cual se actualiza en el momento en que se comprueba en el process que el dato es el que queremos, almacenándose en ese atributo.

El listener nos permite la visualización de ese dato almacenado mediante un método get que devuelve el tipo correspondiente al listener.

Así cuando durante la ejecución de nuestra aplicación necesitemos alguno de los datos, solo tenemos que realizar una espera activa comprobando si tenemos algún dato nuevo en el listener correspondiente al objeto que necesitamos, al que podemos acceder mediante los métodos provistos en la clase contenedor de comunicaciones.

\subsection{Implementación del modelo simple}

\lettrine{D}{bebemos} trabajar haciendo uso de un modelo que simule el comportamiento de una aeronave no tripulada, la estructura de ésta aeronave simulada será por un lado un control que hará de autopiloto, y por otro lado un modelo en Matlab Simulink que será el que haga las veces de sensores y respuestas del avión. Para familiarizarnos con el comportamiento y uso de éstas tecnologías vamos a implementar un llamado \emph{modelo bicicleta} o modelo simple.

\subsubsection{Primera aproximación}

Simulink nos autogenera un código en C++ con el modelo y una serie de métodos para introducir los parámetros de entrada del modelo y un método para ejecutar un paso de simulación. La entra de este modelo simple es el \emph{waypoint} o coordenada al que debe dirigirse y como salida irá mostrando su posición.

Para ésta prueba se realizó un nuevo proyecto que creaba una envoltura al código generado por Simulink, de manera que se le proporcionaba una serie de waypoints y un módulo secuenciador era el encargado de modificar el waypoint objetivo al modelo, ejecutar los pasos de simulación y enviarle el siguiente waypoint cuando hubiera llegado al anterior.

Una vez tuvimos éste sistema funcionando ampliados su funcionamiento para poder usar órdenes externas a través de ánimo, de forma que el control de la ejecución del paso de simulación fuera activada exteriormente, así como la información de la misión que debía realizar.

\subsubsection{Cambios para implementación en el sistema}

La envoltura que se realizó fue una clase llamada AircraftContainer la cual creaba e inicializaba las clases autogeneradas por Matlab Simulink y se encargaba de almacenar los objetos necesarios para el manejo de éste modelo, como por ejemplo el contenedor de comunicaciones, el controlador de ejecución, la clase encargada de secuencia los waypoints al modelo, el controlador de la posición y la encargada del manejo de la carga de misión en nuestro proyecto.

Tiene un método para ejecutar el step del modelo, de forma que primero comprueba si se ha enviado una odre de ejecución desde fuera ya que la ejecución será controlada desde otro módulo. Cuando nos llega una orden de ejecución del paso de simulación, llamamos a la ejecución del controlador de posición que se encargará de modificar el estado de la aeronave y de llamar al guiado que en última instancia será el que compruebe si hemos llegado al waypoint y luego, el controlador de posición llamará a la ejecución del modelo.

Otro método llamado checkMissionRequest comprueba que haya una petición de inicio de carga de misión, el cuál comprobará que no se haya terminado de cargar una misión en curso, y, si se dan las condiciones, inicializar el control de posición.

Por último, checkMissionStartCommand comprueba si ha llegado un comando de inicio de misión, en cuyo caso devolverá verdadero.

La carga de misión se realizará siguiendo el proceso de carga definido por el protocolo Mavlink y será gestionado por la clase MissionLoader, la cual será ejecutada por el contenedor de la aeronave.

Así pues, a cada paso de ejecución, si no hay una misión cargada y llega una solicitud de carga de misión se inicia el proceso de petición de waypoints, una vez está cargada la misión se espera a que se envía una señal de inicio de misión, cuando se cumplen estas dos premisas se comienza la ejecución del modelo cuyos datos recibe mediante el módulo de guiado.

El siguiente paso que realizaremos será el de crear la primera versión del módulo central de control de la simulación, el cuál enviará el paso de simulación y mediante un programa de prueba que haremos podrá validar el funcionamiento de la implementación del modelo simple.

\newpage
\subsection{Diagrama de burndown}

Para este sprint se estimaron 8 puntos, de los cuales se han realizado 11, debido a que una historia de usuario que tenía 3 puntos, concretamente la de set up del entorno se ha realizado en este segundo sprint.

\imgCentradaGrande{fig.4.11}{img/diagvelocidad2.eps}{Diagrama de velocidad para el segundo sprint.}

\newpage
\subsection{Diagrama de evolución}
\imgCentradaGrande{fig.4.12}{img/diagevolucion2.eps}{Diagrama de evolución para el segundo sprint.}

\newpage
\section{Sprint 3: Creación del SIMCORE}

\lettrine{D}{durante} este sprint hemos realizado el desarrollo del módulo central de simulación, proyecto que se encargará de administrar el funcionamiento del resto de módulos, y de crear un proyecto desde el que podamos manejar el envío de datos como si fuera la GCS y que nos sirva para poder realizar pruebas de funcionamiento de una primera versión del sistema de simulación completo.

\subsubsection{SIMCORE}

\lettrine{U}{na} que hemos creado el módulo de manejo de la aeronave y hemos adaptado su funcionamiento a la recepción de datos externos mediante ANIMO DDS haremos una primera versión del módulo central de simulación que el cual se encargará de hacer de puente en el envío de datos entre los diferentes módulos, de asegurarse de que el fluye de datos se está manteniendo bien y de gestionar el envío del paso de ejecución definido por una velocidad en hercios dados por el archivo de configuración del proyecto.

La función de la clase principal del núcleo debe ser la de reenviar los mensajes nuevos recibidos por ánimo, para esto guardará en un atributo de la clase la marca de tiempo que tienen todos los mensajes enviados por ANIMO en un mapa, cada tipo de dato que reciba el simulador tendrá un valor de marca de tiempo guardado en esa variable, de esta manera cuando llegue un dato cuya marca de tiempo difiera de la anterior registrada para ese tipo se reenviará este dato al destinatario correspondiente. En cada paso de iteración el simulador comprobará la marca de tiempo de los datos guardados en los listeners de la capa de comunicación y los cotejará con las guardadas en nuestro mapa de últimas marcas de tiempo de forma que si alguna ha cambiado reenviará el dato.

El tiempo de duración del paso de simulación viene dado por un método que calcula cuánto tiempo debe durar el paso de simulación según los hercios a los que se tenga que ejecutar el simulador, dato que se modifica en el archivo de configuración del proyecto, y cuánto tiempo ha tardado la ejecución de la iteración del simulador de forma que después se pausará un tiempo igual a la diferencia entre el tiempo total que debe durar la ejecución de una iteración y el tiempo que le llevó ejecutar un paso. De esta forma nos aseguramos que todos los pasos de ejecución duran el mismo tiempo y podemos sincronizar el envío y la recepción de datos entre módulos sin que se produzcan errores.

\subsubsection{GCS para pruebas}

Antes de implementar los cambios en la GCS de Catec para que sea posible su comunicación con el resto de módulos mediante ANIMO, realizaremos una aplicación sencilla que se encargue de enviar los mensajes en una secuencia correcta para el sistema de forma que podamos comprobar si la respuesta dada por el simulador es la esperada o hay algún error durante la comunicación con la GCS.

A esta aplicación se le hizo una interfaz a través de la línea de comandos que te permitía enviar varias órdenes. El funcionamiento básico consistía en enviar un comando de mission request en el que se indicaba el número de waypoints que se le iban a enviar y luego ir enviando waypoints generados aleatoriamente.

\subsection{Diagrama de burndown}

En este sprint teníamos como objetivo crear la primera versión funcional del simulador y crear una herramienta que nos permitiera probar el sistema, que es la versión de prueba de la GCS. Las dos acciones fueron finalizadas en éste sprint por lo tanto se cumplieron los objetivos. Al final se realizó una prueba global de todo el sistema que confirmaba que todas sus partes funcionaban correctamente y terminamos una primera versión del sistema de simulación funcionando.

\imgCentradaGrande{fig.4.13}{img/diagvelocidad3.eps}{Diagrama de velocidad para el tercer sprint.}

\subsection{Diagrama de evolución}
\imgCentradaGrande{fig.4.14}{img/diagevolucion3.eps}{Diagrama de evolución para el tercer sprint.}


\newpage
\section{Sprint 4: Implementación del modelo de Locomove}

\lettrine{E}{l} siguiente paso que tomaremos será el de cambiar el modelo simple por el modelo del UAV de Catec Locomove que será el que usemos finalmente de forma que tengamos una respuesta fiable y exacta del comportamiento de la aeronave. El modelo simple que estábamos usando hasta ahora simplemente calculaba una trayectoria rectilínea entre el punto en que se encontraba en ese momento y el punto de destino que tenía que alcanzar y como salida iba actualizando su posición. Sin embargo el modelo del Locomove tiene más parámetros de entrada y en su salida nos da también más datos del estado de la aeronave. Hablaremos muy brevemente del uso de Simulink para la creación de un modelo de simulación y luego analizaremos los cambios realizados para la implementación de éste modelo.

\subsection{Modelos de simulación en Matlab Simulink}

\lettrine{E}{s} un entorno visual de programación que funciona sobre el sistema Matlab. La programación se realiza a un nivel más alto que el lenguaje de programación de Matlab en sí. Es una programación visual donde los componentes de control se incluyen mediante representaciones visuales y la configuración de un programa se realiza como si hiciésemos un mapa de un circuito. Podemos crear "cajas negras" que realizarán una función específica, como si fuesen clases de nuestro programa dentro de las cuales los elementos de entrada irán a parar a funciones que devolverán los parámetros de salida de esas mismas cajas. De esta forma se va formando nuestro programa. 

Este modelo recibirá como parámetros de entrada un grupo de tres waypoints, siendo el primer el waypoint del que procede, el segundo el waypoint al que se debe dirigir y el último el siguiente waypoint que tiene que alcanzar. Como salida seremos capaces de obtener datos de posición, altitud, actitud que nos dirá en qué posición se encuentran los ejes centrales del avión e información sobre el estado de los componentes de la aeronave.

\subsection{Modificaciones en el código para introducir el nuevo modelo}

\lettrine{M}{atlab} Simulink nos genera, a partir del diagrama de cajas creado con su herramienta, un código en C++, el cual debemos integrar en nuestro sistema. El modelo era similar al que teníamos anteriormente hablando de estructura de clases, pero no en entradas y salidas, por lo que no funcionaba nada más implantarlo. Si en un futuro se quisiera modificar de forma sencilla el modelo de avión que se está simulando se debería diseñar unas condiciones estándar que debieran cumplir los modelos en cuestión de parámetros de entrada y salida para que no haya que realizar ninguna modificación en el resto de nuestro código. Una vez se adaptó el sistema de guiado al nuevo modelo, ya que el anterior solo recibía un valor de posición y este espera tres valores, y se subsanaron problemas con los parámetros de entrada de los waypoints, ya que éste simulador comprobaba que la recepción del dato hubiera sido correcta consultando uno de sus parámetros el cual no se había tenido en cuenta anteriormente, fuimos capaces de compilar el proyecto y empezar con las pruebas.

También se modificó la capa de comunicación y, por tanto, se realizaron los cambios pertinentes en el simulador para que aceptase los nuevos tipos que surgieron al introducir el nuevo modelo de avión, ya que algunos parámetros de control no estaban hechos en ANIMO y hubo que añadirlos.

Se realizó una modificación en la funcionalidad de la carga de misión que permitía introducir una nueva misión mientras estaba ejecutando una. De esta forma en pleno vuelo se puede cambiar la trayectoria del avión y darle nuevas órdenes como podría ser la de vuelta a casa o la optimización de la ruta dependiendo de las condiciones actuales del entorno. Por tanto cuando llega una nueva petición de carga de misión, el control de la aeronave guarda en un nuevo atributo la nueva misión cargada y cuando recibe la orden de iniciar dicha misión la sustituye dentro del sistema de guiado para que el avión siga la nueva ruta.

Otro inconveniente a tener en cuenta fue el conflicto que surgió al modelar los tipos de datos de Mavlink a tipos de ANIMO, ya que dos tipos casi idénticos como eran el mission\_count y el mission\_request se modelaron en un mismo tipo de dato denominado mission\_command, este mission\_command se distinguía mediante el tópico que llevaba el dato al ser transportado, ya que por exigencias del protocolo de carga de misión el mission\_count siempre iba a enviarse bajo el tópico de la GCS y el mission\_request siempre lo iba a enviar el control de la aeronave. Por la estructura interna de ANIMO y DDS resulta que los dos datos llegaban a los dos listeners donde se podían discriminar dependiendo del lugar desde el que procedían, sin embargo, al publicarlos el simulador les ponía su propio tópico, ahí era cuando no se podían distinguir en los destinos qué tipo era el que estaba publicando el simulador y esto introducía incoherencias dentro de nuestro sistema. Para solucionar este problema se optó por modelar los datos de Mavlink en ANIMO por separado, al tratarse de dos tipos de datos distintos este problema dejó de darse.

\subsection{Diagrama de burndown}

En este sprint nos comprometimos a realizar la introducción del nuevo modelo y de implementar nuestro sistema con la GCS de Catec, al encontrarnos con muchos problemas a la hora de realizar la implementación de la envoltura del nuevo modelo de avión no pudimos completar todas las historias de usuario de este sprint lo cual se representa como una caída en el rendimiento de la velocidad del equipo de desarrollo.

\imgCentradaGrande{fig.4.15}{img/diagvelocidad4.eps}{Diagrama de velocidad para el cuarto sprint.}

\subsection{Diagrama de evolución}
\imgCentradaGrande{fig.4.15}{img/diagevolucion4.eps}{Diagrama de evolución para el cuarto sprint.}

\newpage
\section{Sprint 5: Introducción de la GCS de Catec}

\lettrine{E}{n} este sprint vamos a introducir en nuestro sistema la GCS de Catec, uno de los objetivos fundamentales consistía en que el alumno que fuera a usar nuestra plataforma con el fin de realizar prácticas de vuelo no tripulado debía de ser conocedor y de poder trabajar con la herramienta de control de aviones no tripulados de Catec o estación de control de tierra. Por ello después de las pruebas iniciales de funcionamiento del simulador nos dispondremos a integrar la herramienta real al sistema. Primero explicaremos el uso de una herramienta que nos aseguró que la aeronave estaba siguiendo las rutas correctamente.

\subsection{Visualizador basado en Marble y problema de loiter}

\lettrine{H}{asta} ahora la única forma que hemos tenido de visualizar el progreso de una misión en curso era imprimiendo en la salida estándar de nuestro sistema operativo la posición y los datos que nos eran relevantes y comprobar la dirección en la que se movían según las coordenadas o ver si se acercaba al punto que le indicábamos, pero esta es una forma muy poco intuitiva y no podemos ver potenciales errores en el movimiento de la aeronave, por ello y antes de introducir la GCS en el sistema creamos una herramienta de visualización basada en Marble.

Marble es una aplicación geográfica desarrollada por KDE y distribuida bajo licencia GNU LGPL y nos provee herramientas parecidas a las de Google Maps, pudiendo representar sobre un mapa terrestre una posición dando sus coordenadas globales. Nuestra aplicación era muy simple y solo consistía en una ventana en la cual se representaba el mapa y sobre él la posición de la aeronave. 

Para tomar estos datos nos subscribíamos por ANIMO DDS al dato de posición y lo actualizábamos según un ratio de refresco prefijado. Gracias al patrón publicador subscriptor nos fue muy sencillo realizar una aplicación de este estilo ya que únicamente sabiendo el tópico y el tipo de dato mediante una configuración sencilla de la herramienta de ANIMO pudimos recoger el dato actualizado y representarlo.

Una vez usada ésta herramienta hicimos dos comprobaciones, la primera era que cuando se realiza una misión de un solo waypoint, según el comportamiento observado por los datos de posición pensábamos que el modelo del avión se quedaba girando en torno al waypoint, al poder observarlo en el mapa nos dimos cuenta de que no giraba en torno al waypoint sino que una vez llegado a él intentaba volver a alcanzarlo haciendo que se forzase la aeronave a realizar giros pronunciados, lo cual se debía corregir ya que podría producirse algún error por este motivo.

La otra observación fue la del funcionamiento del waypoint tipo loiter. Los waypoints tienen una serie de atributos de comandos para indicar acciones cuando se llegue a ellos, una de estas acciones es la de hacer lioter, que consiste en girar con un radio dado por un parámetro en el mismo waypoint usando el waypoint como centro de la circunferencia a trazar. En el modelo de Simulink el loiter anulaba el módulo que generaba el mensaje de aviso de que se había alcanzado un waypoint, este mensaje se denomina "detect", el loiter, al tener que mantener el avión girando en torno a un waypoint no debe activar el detect por que si no el sistema de guiado mandaría el siguiente waypoint, sin embargo, el modelo de simulink guardaba el último valor obtenido en el detect, por tanto cuando llegaba al waypoint anterior y se cambiaba al loiter se mantiene el valor del detect y para el sistema es como si hubiera llegado por lo que se lo saltaba.



\subsection{Introducción de la GCS}

\lettrine{A}{} la hora de introducir la GCS el primer paso consiste en realizar la instalación. La instalación requiere de una serie de dependencias y librerías que al ser ajenas al proyecto actual no voy a enumerar, pero requiere de tener instalados Qt5 principalmente ya que hace mucho uso de señales, de las cuales os hablaré en el último capítulo de este apartado. 

El uso hasta ahora que se había hecho de la GCS usaba comunicaciones mediante el protocolo UDP, por tanto tanto el protocolo de Mavlink como la GCS están preparadas para comunicarse de esta manera. Pero por la forma en que está diseñada la GCS podemos aprovechar las señales que emite para conectarlas con una aplicación externa.

Al estar la GCS basada en plugins podemos usar esta funcionalidad para crear una interfaz para las comunicaciones mediante DDS RTI con ANIMO. La funcionalidad de nuestro plugin será principalmente recoger los datos publicados por el simulador que van destinados hacia la GCS, realizar una traducción del dato de ANIMO a un dato de las interfaces de Mavlink (que son los datos que trabjan en la GCS) e introducirlos en el sistema de la GCS, recogiendo la respuesta de ésta, volviendo a realizar la traducción externa y publicar estos datos mediante ANIMO.

Debido a que la clase que recoge los datos por UDP para tratarlos como la que los publica por este medio se une con estos sistemas mediante señales de Qt vamos a aprovecharnos de esta funcionalidad. Las señales de Qt con una herramienta mediante las que puedes unir dos métodos de dos clases cualesquiera, aunque no compartan dependencias ni relación de forma que puedas pasarle parámetros, un método emite una señal y esa señal se trata en un bucle específico de Qt y se envía al método con el que se haya realizado la conexión. De esta forma crearemos un nuevo tipo de listener que heredará de nuestro listener de ANIMO pero añadirá la funcionalidad de emitir señales de Qt cuando le haya llegado un nuevo dato. Así no tendremos que estar consultando el dato almacenado en el listener, sino que sabremos cuando ha llegado un dato nuevo. Cuando llega un dato nuevo se emite una señal que durante la instanciación del plugin ha sido conectada con el método de la GCS que se dedica a tratar los datos que provienen de fuera de la aplicación. De la misma forma cuando la GCS tiene que enviar un dato emite una señal, la cual conectaremos con la clase del plugin que realiza la publicación mediante ANIMO.

Para finalizar se realizó una interfaz al plugin de forma que mediante un formulario se pudiera configurar los parámetros de ANIMO.

\subsection{Diagrama de burndown}

Este sprint se dedicó al funcionamiento de la GCS casi en su totalidad, ya que no solo debimos instalarla sino averiguar su funcionamiento tras horas de lectura de su código y del estudio de Qt, por tanto nos llevó más tiempo del esperado y la integración de nuestro plugin no se terminó en este sprint sino en el siguiente, por eso las gráficas muestran que no ha habido una evolución en las historias de usuario.

\imgCentradaGrande{fig.4.17}{img/diagvelocidad5.eps}{Diagrama de velocidad para el quinto sprint.}

\subsection{Diagrama de evolución}
\imgCentradaGrande{fig.4.18}{img/diagevolucion5.eps}{Diagrama de evolución para el quinto sprint.}

\newpage
\section{Sprint 6: Puesto de instructor}

\lettrine{D}{durante} este sprint nos centraremos en realizar el diseño y set up del proyecto del puesto de instructor y de implementar las funcionalidades necesarias en el mismo. Haremos un repaso sobre qué componentes y tecnologías usa y luego enumeraremos sus distintas funcionalidades y como se han implementado.

\subsubsection{Estructura y set up}

\lettrine{A}{l} ser un proyecto web en Java podemos aprovechar la gran cantidad de frameworks, librerías y herramientas que existen para éste fin y que nos facilitan tanto el desarrollo como el futuro mantenimiento y posible cambio de la funcionalidad de la aplicación. Por supuesto haremos uso de la metodología de programación denominada inversión de control que nos permitirá más flexibilidad a la hora de implementar las dependencias, ya que todos los objetos son creados en un contenedor al cual podemos acceder llamando una instancia del mismo desde cualquier parte del código y que nos proveerá de los objetos que necesitemos sin que tengamos que estar encapsulando objetos unos en otros. Ésta técnica la implementaremos mediante el uso del framework Spring, el cual a parte de ésta funcionalidad nos provee de muchas más herramientas útiles, por ejemplo, a la hora de implementar la persistencia de datos.

Para la vista web como para la implementación del Modelo-Vista-Controlador usaremos Struts 2 con Convention Plugin. Esto nos permitirá unir las acciones a la vista de forma sencilla e intuitiva, de forma que podamos unir nuestras clases java con las peticiones realizadas por el usuario desde el navegador.

También implementamos la persistencia con Hibernate de forma que automáticamente nos crease una base de datos con las tablas que necesitásemos. El uso de esta base de datos aún no está implementado pero en un futuro si podrá funcionar con la implementación que realizamos.

Todas las dependencias vienen gestionada mediante Maven, al tener tantas tecnologías trabajando juntas tenemos el problema que algunas de ellas comparten librerías por lo que puede haber errores a la hora de instalar las versiones de cada una de ellas, esto supuso un gran problema de manera que cuando conseguimos hacer funcionar todas nos creamos mediante Maven un arquetipo que nos permitiera guardar un set up de proyecto de forma que la próxima vez que se realizara un proyecto de éstas características tendríamos ya todo configurado.

Los más complicado fue añadir DDS RTI al proyecto del puesto de instructor, ya que ANIMO no tiene librerías para Java, solo para C++, de forma que tuvimos que implementar directamente una envoltura para RTI DDS que funciona a mucho más bajo nivel, de forma que teníamos que gestionar las calidades de servicios, la creación de los participantes que son los objetos encargados del envío y recepción de datos por la red y de crear los objetos IDL para cada uno de los datos que teníamos que enviar. Todo esto lo hace ANIMO automáticamente pero al no poder usarlo hicimos una implementación manual de las librerías de RTI. Al adaptarlo el funcionamiento es parecido al del resto de módulos, tenemos una serie de listeners que almacenan el dato recibido.

El último paso para tenerlo todo funcionando y probar es instalarnos Tomcat que lo usaremos en su versión 7. Tomcat es un contenedor de servlets e implementa las especificaciones de los servlets de JavaServer Pages (JSP) de Oracle, que usaremos para programar las vistas de nuestro puesto de instructor. Una vez instalado solo debemos crear nuestro paquete .war directamente desde el IDE de Java y desplegarlos sobre tomcat para tener nuestro servidor funcionando y poder acceder a la página web.

\subsubsection{Funcionalidad del puesto de instructor}

\lettrine{L}{a} funcionalidad principal del puesto de instructor se basa en dos puntos claves, por un lado monitorizar las acciones del alumno durante la misión de prácticas o de examen y por otra parte ser capaz de controlar los parámetros de la misión e introducir errores.

El primer paso fue crear una serie de estados en el simulador que nos permitiera controlar el paso de ejecución de forma que se pausara y se pudiera reanudar. Para ello se crea una clase en el simulador que se dedica al tratamiento de los comandos de control de la misión, esta clase discrimina entre los diferentes comandos implementados y controla el envío del paso de simulación. Luego se implementaron una serie de botones en la vista que cuya función simplemente residía en enviar mediante ANIMO el mensaje correspondiente.

\subsection{Diagrama de burndown}

Las tareas para este sprint fueron, a parte de acabar las que no se terminaron en el anterior, crear una primera versión del puesto de instructor, la cual se realizó satisfactoriamente ya que funcionaba bien con el resto de componentes.

\imgCentradaGrande{fig.4.19}{img/diagvelocidad6.eps}{Diagrama de velocidad para el sexto sprint.}

\subsection{Diagrama de evolución}

\imgCentradaGrande{fig.4.20}{img/diagevolucion6.eps}{Diagrama de velocidad para el sexto sprint.}

\newpage
\section{Sprint 7: Primera versión y cambios en el objetivo}

\lettrine{C}{uando} tuvimos la reunión de retrospectiva del sprint anterior analizamos el estado y el funcionamiento del proyecto y los cambios que se deberían realizar para mejorar la funcionalidad. Durante esta reunión decidimos que el mantenimiento y desarrollo de la aplicación de controlador y envoltura del modelo del UAV resultaba muy costoso y nos retrasaba mucho ya que cualquier cambio en el resto del sistema suponía tener que tocar la forma en que se interaccionaba con el modelo. Además el equipo de aviónica tiene modelos de prueba integrados con el control y una máquina de estados que tendríamos que implementar nosotros en nuestro control de envoltura del modelo cuando ellos ya lo tienen probado y es el control que va en el autopiloto real del avión. También se hizo hincapié en tener control sobre la misión, ahora en la primera versión del puesto de instructor somos capaces de pausar y reanudar la misión pero también deberíamos controlar el inicio y el fin de la misma. La última observación fue sobre la función del núcleo del simulador, ahora pasan por él todos los mensajes y la única acción que realiza es la de reenviarlos. A continuación repasaremos estos tres puntos revisando los pros y los contras de las dos versiones propuestas.

\subsection{Análisis del estado del proyecto}

\lettrine{L}{a} modificación más radical fue la de usar el autopiloto embarcado como medio de simulación de la aeronave, 

\subsection{Diagrama de burndown}
%\imgCentradaGrande{fig.4.21}{img/diagvelocidad7.eps}{Diagrama de velocidad para el séptimo sprint.}

\newpage
\section{Sprint 8: Cambios en el diseño}

\subsection{Diagrama de burndown}
%\imgCentradaGrande{fig.4.23}{img/diagvelocidad8.eps}{Diagrama de velocidad para el octavo sprint.}

\part{Conclusiones}

\part{Apéndices}

\end{document}
